{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "kgKFC5qUtsOr",
        "outputId": "6fc32fa6-00ed-41ff-9869-48635f0210b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>encounter_id</th>\n",
              "      <th>hospital_id</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>elective_surgery</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>gender</th>\n",
              "      <th>height</th>\n",
              "      <th>hospital_admit_source</th>\n",
              "      <th>...</th>\n",
              "      <th>h1_pao2fio2ratio_max</th>\n",
              "      <th>h1_pao2fio2ratio_min</th>\n",
              "      <th>aids</th>\n",
              "      <th>cirrhosis</th>\n",
              "      <th>hepatic_failure</th>\n",
              "      <th>immunosuppression</th>\n",
              "      <th>leukemia</th>\n",
              "      <th>lymphoma</th>\n",
              "      <th>solid_tumor_with_metastasis</th>\n",
              "      <th>diabetes_mellitus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>214826</td>\n",
              "      <td>118</td>\n",
              "      <td>68.0</td>\n",
              "      <td>22.732803</td>\n",
              "      <td>0</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>M</td>\n",
              "      <td>180.3</td>\n",
              "      <td>Floor</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>246060</td>\n",
              "      <td>81</td>\n",
              "      <td>77.0</td>\n",
              "      <td>27.421875</td>\n",
              "      <td>0</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>F</td>\n",
              "      <td>160.0</td>\n",
              "      <td>Floor</td>\n",
              "      <td>...</td>\n",
              "      <td>51.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>276985</td>\n",
              "      <td>118</td>\n",
              "      <td>25.0</td>\n",
              "      <td>31.952749</td>\n",
              "      <td>0</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>F</td>\n",
              "      <td>172.7</td>\n",
              "      <td>Emergency Department</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>262220</td>\n",
              "      <td>118</td>\n",
              "      <td>81.0</td>\n",
              "      <td>22.635548</td>\n",
              "      <td>1</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>F</td>\n",
              "      <td>165.1</td>\n",
              "      <td>Operating Room</td>\n",
              "      <td>...</td>\n",
              "      <td>337.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>201746</td>\n",
              "      <td>33</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>M</td>\n",
              "      <td>188.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 181 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  encounter_id  hospital_id   age        bmi  elective_surgery  \\\n",
              "0           1        214826          118  68.0  22.732803                 0   \n",
              "1           2        246060           81  77.0  27.421875                 0   \n",
              "2           3        276985          118  25.0  31.952749                 0   \n",
              "3           4        262220          118  81.0  22.635548                 1   \n",
              "4           5        201746           33  19.0        NaN                 0   \n",
              "\n",
              "   ethnicity gender  height hospital_admit_source  ... h1_pao2fio2ratio_max  \\\n",
              "0  Caucasian      M   180.3                 Floor  ...                  NaN   \n",
              "1  Caucasian      F   160.0                 Floor  ...                 51.0   \n",
              "2  Caucasian      F   172.7  Emergency Department  ...                  NaN   \n",
              "3  Caucasian      F   165.1        Operating Room  ...                337.0   \n",
              "4  Caucasian      M   188.0                   NaN  ...                  NaN   \n",
              "\n",
              "   h1_pao2fio2ratio_min aids cirrhosis  hepatic_failure  immunosuppression  \\\n",
              "0                   NaN    0         0                0                  0   \n",
              "1                  51.0    0         0                0                  0   \n",
              "2                   NaN    0         0                0                  0   \n",
              "3                 337.0    0         0                0                  0   \n",
              "4                   NaN    0         0                0                  0   \n",
              "\n",
              "   leukemia  lymphoma  solid_tumor_with_metastasis  diabetes_mellitus  \n",
              "0         0         0                            0                  1  \n",
              "1         0         0                            0                  1  \n",
              "2         0         0                            0                  0  \n",
              "3         0         0                            0                  0  \n",
              "4         0         0                            0                  0  \n",
              "\n",
              "[5 rows x 181 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#  Import and read the diabetes_w_in_24hr.csv.\n",
        "import pandas as pd\n",
        "diabetes_df = pd.read_csv('https://raw.githubusercontent.com/ComfyKoala/diabetes-classification/main/Nikko/Resources/Diabetes_w_in_24hr.csv')\n",
        "# Display the first few rows\n",
        "diabetes_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTE3kuIWN2Po"
      },
      "source": [
        "# Clean, Standardize, and Encode Categorical Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M2zjKOxr0HUU"
      },
      "outputs": [],
      "source": [
        "# remove extra info\n",
        "# reduced dataset to measurements taken within 24 hours (as opposed to only within the first hour after admission)\n",
        "# simplified invasive/noninvasive/combined measurements to only the combined measurements\n",
        "clean_diabetes_df = diabetes_df.drop(columns=['Unnamed: 0', 'encounter_id', 'hospital_id', 'elective_surgery', 'icu_admit_source', 'icu_id',\n",
        "                                              'icu_stay_type', 'icu_type', 'pre_icu_los_days', 'readmission_status', 'd1_diasbp_invasive_max', 'd1_diasbp_invasive_min',\n",
        "                                              'd1_diasbp_noninvasive_max', 'd1_diasbp_noninvasive_min', 'd1_mbp_invasive_max', 'd1_mbp_invasive_min',\n",
        "                                              'd1_mbp_noninvasive_max', 'd1_mbp_noninvasive_min', 'd1_resprate_max', 'd1_resprate_min', 'd1_sysbp_invasive_max',\n",
        "                                              'd1_sysbp_invasive_min', 'd1_sysbp_noninvasive_max', 'd1_sysbp_noninvasive_min', 'h1_diasbp_invasive_max',\n",
        "                                              'h1_diasbp_invasive_min', 'h1_diasbp_max', 'h1_diasbp_min', 'h1_diasbp_noninvasive_max', 'h1_diasbp_noninvasive_min',\n",
        "                                              'h1_heartrate_max', 'h1_heartrate_min', 'h1_mbp_invasive_max', 'h1_mbp_invasive_min', 'h1_mbp_max', 'h1_mbp_min',\n",
        "                                              'h1_mbp_noninvasive_max', 'h1_mbp_noninvasive_min', 'h1_resprate_max', 'h1_resprate_min', 'h1_spo2_max', 'h1_spo2_min',\n",
        "                                              'h1_sysbp_invasive_max', 'h1_sysbp_invasive_min', 'h1_sysbp_max', 'h1_sysbp_min', 'h1_sysbp_noninvasive_max',\n",
        "                                              'h1_sysbp_noninvasive_min', 'h1_temp_max', 'h1_temp_min', 'h1_albumin_max', 'h1_albumin_min', 'h1_bilirubin_max',\n",
        "                                              'h1_bilirubin_min', 'h1_bun_max', 'h1_bun_min', 'h1_calcium_max', 'h1_calcium_min', 'h1_creatinine_max',\n",
        "                                              'h1_creatinine_min', 'h1_glucose_max', 'h1_glucose_min', 'h1_hco3_max', 'h1_hco3_min', 'h1_hemaglobin_max',\n",
        "                                              'h1_hemaglobin_min', 'h1_hematocrit_max', 'h1_hematocrit_min', 'h1_inr_max', 'h1_inr_min', 'h1_lactate_max',\n",
        "                                              'h1_lactate_min', 'h1_platelets_max', 'h1_platelets_min', 'h1_potassium_max', 'h1_potassium_min', 'h1_sodium_max',\n",
        "                                              'h1_sodium_min', 'h1_wbc_max', 'h1_wbc_min', 'h1_arterial_pco2_max', 'h1_arterial_pco2_min', 'h1_arterial_ph_max',\n",
        "                                              'h1_arterial_ph_min', 'h1_arterial_po2_max', 'h1_arterial_po2_min', 'h1_pao2fio2ratio_max', 'h1_pao2fio2ratio_min', 'solid_tumor_with_metastasis'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9qJ6vqHk8h64"
      },
      "outputs": [],
      "source": [
        "# count nulls, remove columns where null values exist for > 5000 of the rows\n",
        "null_col_check = clean_diabetes_df.isnull().sum(axis=0)\n",
        "null_col_check = null_col_check[null_col_check != 0][null_col_check > 5000]\n",
        "remove_cols = []\n",
        "for i, v in null_col_check.items():\n",
        "  remove_cols.append(i)\n",
        "\n",
        "clean_diabetes_df = clean_diabetes_df.drop(columns=remove_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6caPdd448oH6"
      },
      "outputs": [],
      "source": [
        "# then decide which columns to remove altogether and which rows to remove due to nulls\n",
        "null_row_check = clean_diabetes_df.isnull().sum(axis=1)\n",
        "null_row_check = null_row_check[null_row_check != 0]\n",
        "remove_rows = []\n",
        "for i, v in null_row_check.items():\n",
        "  remove_rows.append(i)\n",
        "\n",
        "clean_diabetes_df = clean_diabetes_df.drop(remove_rows, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "aawirTTQHJPK",
        "outputId": "9475c6dc-9f3e-47c6-ffad-a41b39b032f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>gcs_eyes_apache</th>\n",
              "      <th>gcs_motor_apache</th>\n",
              "      <th>gcs_verbal_apache</th>\n",
              "      <th>glucose_apache</th>\n",
              "      <th>heart_rate_apache</th>\n",
              "      <th>map_apache</th>\n",
              "      <th>...</th>\n",
              "      <th>d1_mbp_max</th>\n",
              "      <th>d1_mbp_min</th>\n",
              "      <th>d1_spo2_max</th>\n",
              "      <th>d1_spo2_min</th>\n",
              "      <th>d1_sysbp_max</th>\n",
              "      <th>d1_sysbp_min</th>\n",
              "      <th>d1_temp_max</th>\n",
              "      <th>d1_temp_min</th>\n",
              "      <th>d1_glucose_max</th>\n",
              "      <th>d1_glucose_min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.297782</td>\n",
              "      <td>-0.793148</td>\n",
              "      <td>0.992934</td>\n",
              "      <td>-0.419735</td>\n",
              "      <td>-0.404177</td>\n",
              "      <td>0.431091</td>\n",
              "      <td>0.077494</td>\n",
              "      <td>0.091107</td>\n",
              "      <td>0.579069</td>\n",
              "      <td>-1.109528</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.720101</td>\n",
              "      <td>-1.222879</td>\n",
              "      <td>0.425570</td>\n",
              "      <td>-1.640611</td>\n",
              "      <td>-0.698524</td>\n",
              "      <td>-1.165315</td>\n",
              "      <td>3.675103</td>\n",
              "      <td>1.264498</td>\n",
              "      <td>-0.116867</td>\n",
              "      <td>-0.095852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.847794</td>\n",
              "      <td>-0.230513</td>\n",
              "      <td>-0.898754</td>\n",
              "      <td>-0.567104</td>\n",
              "      <td>-2.417341</td>\n",
              "      <td>-1.789454</td>\n",
              "      <td>-1.773937</td>\n",
              "      <td>-0.161242</td>\n",
              "      <td>0.644658</td>\n",
              "      <td>-0.967542</td>\n",
              "      <td>...</td>\n",
              "      <td>0.768477</td>\n",
              "      <td>-1.769419</td>\n",
              "      <td>0.425570</td>\n",
              "      <td>-2.043081</td>\n",
              "      <td>0.390071</td>\n",
              "      <td>-1.469907</td>\n",
              "      <td>-1.486185</td>\n",
              "      <td>-1.518845</td>\n",
              "      <td>-0.379037</td>\n",
              "      <td>0.414135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.092244</td>\n",
              "      <td>-0.804818</td>\n",
              "      <td>-0.423502</td>\n",
              "      <td>-0.905654</td>\n",
              "      <td>0.602404</td>\n",
              "      <td>0.431091</td>\n",
              "      <td>0.694638</td>\n",
              "      <td>0.277626</td>\n",
              "      <td>0.447890</td>\n",
              "      <td>-0.636242</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.960194</td>\n",
              "      <td>1.373186</td>\n",
              "      <td>0.425570</td>\n",
              "      <td>0.472356</td>\n",
              "      <td>0.351192</td>\n",
              "      <td>-0.606897</td>\n",
              "      <td>0.951090</td>\n",
              "      <td>-1.916465</td>\n",
              "      <td>0.076911</td>\n",
              "      <td>-0.659522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.236669</td>\n",
              "      <td>-0.214467</td>\n",
              "      <td>1.943437</td>\n",
              "      <td>0.619812</td>\n",
              "      <td>0.602404</td>\n",
              "      <td>0.431091</td>\n",
              "      <td>0.694638</td>\n",
              "      <td>-0.040553</td>\n",
              "      <td>0.415096</td>\n",
              "      <td>1.020258</td>\n",
              "      <td>...</td>\n",
              "      <td>1.104607</td>\n",
              "      <td>1.099916</td>\n",
              "      <td>-1.671398</td>\n",
              "      <td>0.069886</td>\n",
              "      <td>0.934368</td>\n",
              "      <td>0.560705</td>\n",
              "      <td>-0.769340</td>\n",
              "      <td>0.469257</td>\n",
              "      <td>-0.253651</td>\n",
              "      <td>0.333611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.252231</td>\n",
              "      <td>3.372639</td>\n",
              "      <td>-0.423502</td>\n",
              "      <td>2.874156</td>\n",
              "      <td>0.602404</td>\n",
              "      <td>0.431091</td>\n",
              "      <td>0.694638</td>\n",
              "      <td>0.409287</td>\n",
              "      <td>1.070988</td>\n",
              "      <td>1.209573</td>\n",
              "      <td>...</td>\n",
              "      <td>0.624421</td>\n",
              "      <td>2.261314</td>\n",
              "      <td>0.425570</td>\n",
              "      <td>-0.332584</td>\n",
              "      <td>0.079044</td>\n",
              "      <td>1.880603</td>\n",
              "      <td>-0.195863</td>\n",
              "      <td>-1.651385</td>\n",
              "      <td>0.213695</td>\n",
              "      <td>0.440976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38181</th>\n",
              "      <td>0.358894</td>\n",
              "      <td>0.069880</td>\n",
              "      <td>1.943437</td>\n",
              "      <td>0.962345</td>\n",
              "      <td>-2.417341</td>\n",
              "      <td>-1.049272</td>\n",
              "      <td>-1.773937</td>\n",
              "      <td>-0.051525</td>\n",
              "      <td>-1.749348</td>\n",
              "      <td>-0.565249</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.248306</td>\n",
              "      <td>-0.061481</td>\n",
              "      <td>0.425570</td>\n",
              "      <td>0.572974</td>\n",
              "      <td>-0.854038</td>\n",
              "      <td>0.357644</td>\n",
              "      <td>-0.625970</td>\n",
              "      <td>-0.060903</td>\n",
              "      <td>-0.196658</td>\n",
              "      <td>0.092038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38182</th>\n",
              "      <td>0.236669</td>\n",
              "      <td>0.369629</td>\n",
              "      <td>0.759967</td>\n",
              "      <td>0.719385</td>\n",
              "      <td>-2.417341</td>\n",
              "      <td>-0.309091</td>\n",
              "      <td>-1.773937</td>\n",
              "      <td>-0.479421</td>\n",
              "      <td>0.611863</td>\n",
              "      <td>-0.872885</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.191896</td>\n",
              "      <td>-0.812974</td>\n",
              "      <td>-0.273420</td>\n",
              "      <td>-0.433201</td>\n",
              "      <td>-1.126186</td>\n",
              "      <td>-1.013019</td>\n",
              "      <td>-1.342816</td>\n",
              "      <td>-0.856144</td>\n",
              "      <td>-0.333442</td>\n",
              "      <td>0.092038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38183</th>\n",
              "      <td>1.153357</td>\n",
              "      <td>1.679250</td>\n",
              "      <td>-3.023408</td>\n",
              "      <td>-0.579053</td>\n",
              "      <td>0.602404</td>\n",
              "      <td>-0.309091</td>\n",
              "      <td>-1.773937</td>\n",
              "      <td>-0.216100</td>\n",
              "      <td>-0.044029</td>\n",
              "      <td>0.830944</td>\n",
              "      <td>...</td>\n",
              "      <td>0.864514</td>\n",
              "      <td>0.416741</td>\n",
              "      <td>-0.972409</td>\n",
              "      <td>-0.030731</td>\n",
              "      <td>1.012125</td>\n",
              "      <td>0.053052</td>\n",
              "      <td>-0.769340</td>\n",
              "      <td>-0.723604</td>\n",
              "      <td>-0.219455</td>\n",
              "      <td>0.279928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38184</th>\n",
              "      <td>1.520032</td>\n",
              "      <td>-1.273530</td>\n",
              "      <td>-0.190536</td>\n",
              "      <td>-1.267703</td>\n",
              "      <td>-1.410759</td>\n",
              "      <td>-0.309091</td>\n",
              "      <td>-1.773937</td>\n",
              "      <td>0.244711</td>\n",
              "      <td>0.480685</td>\n",
              "      <td>1.185909</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.047840</td>\n",
              "      <td>0.485059</td>\n",
              "      <td>0.425570</td>\n",
              "      <td>0.874826</td>\n",
              "      <td>-0.037591</td>\n",
              "      <td>0.154582</td>\n",
              "      <td>-0.912709</td>\n",
              "      <td>0.204177</td>\n",
              "      <td>0.042715</td>\n",
              "      <td>0.870439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38185</th>\n",
              "      <td>-2.024494</td>\n",
              "      <td>-0.030827</td>\n",
              "      <td>-0.656469</td>\n",
              "      <td>-0.300247</td>\n",
              "      <td>0.602404</td>\n",
              "      <td>0.431091</td>\n",
              "      <td>0.694638</td>\n",
              "      <td>-0.786628</td>\n",
              "      <td>1.333345</td>\n",
              "      <td>-0.517921</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.912175</td>\n",
              "      <td>0.143471</td>\n",
              "      <td>0.425570</td>\n",
              "      <td>0.371739</td>\n",
              "      <td>-1.242822</td>\n",
              "      <td>-0.353070</td>\n",
              "      <td>0.090875</td>\n",
              "      <td>0.601797</td>\n",
              "      <td>-0.971769</td>\n",
              "      <td>-0.659522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38186 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            age       bmi    height    weight  gcs_eyes_apache  \\\n",
              "0      0.297782 -0.793148  0.992934 -0.419735        -0.404177   \n",
              "1      0.847794 -0.230513 -0.898754 -0.567104        -2.417341   \n",
              "2      1.092244 -0.804818 -0.423502 -0.905654         0.602404   \n",
              "3      0.236669 -0.214467  1.943437  0.619812         0.602404   \n",
              "4     -0.252231  3.372639 -0.423502  2.874156         0.602404   \n",
              "...         ...       ...       ...       ...              ...   \n",
              "38181  0.358894  0.069880  1.943437  0.962345        -2.417341   \n",
              "38182  0.236669  0.369629  0.759967  0.719385        -2.417341   \n",
              "38183  1.153357  1.679250 -3.023408 -0.579053         0.602404   \n",
              "38184  1.520032 -1.273530 -0.190536 -1.267703        -1.410759   \n",
              "38185 -2.024494 -0.030827 -0.656469 -0.300247         0.602404   \n",
              "\n",
              "       gcs_motor_apache  gcs_verbal_apache  glucose_apache  heart_rate_apache  \\\n",
              "0              0.431091           0.077494        0.091107           0.579069   \n",
              "1             -1.789454          -1.773937       -0.161242           0.644658   \n",
              "2              0.431091           0.694638        0.277626           0.447890   \n",
              "3              0.431091           0.694638       -0.040553           0.415096   \n",
              "4              0.431091           0.694638        0.409287           1.070988   \n",
              "...                 ...                ...             ...                ...   \n",
              "38181         -1.049272          -1.773937       -0.051525          -1.749348   \n",
              "38182         -0.309091          -1.773937       -0.479421           0.611863   \n",
              "38183         -0.309091          -1.773937       -0.216100          -0.044029   \n",
              "38184         -0.309091          -1.773937        0.244711           0.480685   \n",
              "38185          0.431091           0.694638       -0.786628           1.333345   \n",
              "\n",
              "       map_apache  ...  d1_mbp_max  d1_mbp_min  d1_spo2_max  d1_spo2_min  \\\n",
              "0       -1.109528  ...   -0.720101   -1.222879     0.425570    -1.640611   \n",
              "1       -0.967542  ...    0.768477   -1.769419     0.425570    -2.043081   \n",
              "2       -0.636242  ...   -0.960194    1.373186     0.425570     0.472356   \n",
              "3        1.020258  ...    1.104607    1.099916    -1.671398     0.069886   \n",
              "4        1.209573  ...    0.624421    2.261314     0.425570    -0.332584   \n",
              "...           ...  ...         ...         ...          ...          ...   \n",
              "38181   -0.565249  ...   -1.248306   -0.061481     0.425570     0.572974   \n",
              "38182   -0.872885  ...   -0.191896   -0.812974    -0.273420    -0.433201   \n",
              "38183    0.830944  ...    0.864514    0.416741    -0.972409    -0.030731   \n",
              "38184    1.185909  ...   -0.047840    0.485059     0.425570     0.874826   \n",
              "38185   -0.517921  ...   -0.912175    0.143471     0.425570     0.371739   \n",
              "\n",
              "       d1_sysbp_max  d1_sysbp_min  d1_temp_max  d1_temp_min  d1_glucose_max  \\\n",
              "0         -0.698524     -1.165315     3.675103     1.264498       -0.116867   \n",
              "1          0.390071     -1.469907    -1.486185    -1.518845       -0.379037   \n",
              "2          0.351192     -0.606897     0.951090    -1.916465        0.076911   \n",
              "3          0.934368      0.560705    -0.769340     0.469257       -0.253651   \n",
              "4          0.079044      1.880603    -0.195863    -1.651385        0.213695   \n",
              "...             ...           ...          ...          ...             ...   \n",
              "38181     -0.854038      0.357644    -0.625970    -0.060903       -0.196658   \n",
              "38182     -1.126186     -1.013019    -1.342816    -0.856144       -0.333442   \n",
              "38183      1.012125      0.053052    -0.769340    -0.723604       -0.219455   \n",
              "38184     -0.037591      0.154582    -0.912709     0.204177        0.042715   \n",
              "38185     -1.242822     -0.353070     0.090875     0.601797       -0.971769   \n",
              "\n",
              "       d1_glucose_min  \n",
              "0           -0.095852  \n",
              "1            0.414135  \n",
              "2           -0.659522  \n",
              "3            0.333611  \n",
              "4            0.440976  \n",
              "...               ...  \n",
              "38181        0.092038  \n",
              "38182        0.092038  \n",
              "38183        0.279928  \n",
              "38184        0.870439  \n",
              "38185       -0.659522  \n",
              "\n",
              "[38186 rows x 26 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# scale numerical columns due to large differences in values\n",
        "scaled_data = StandardScaler().fit_transform(clean_diabetes_df[['age', 'bmi', 'height', 'weight', 'gcs_eyes_apache', 'gcs_motor_apache',\n",
        "                                                                'gcs_verbal_apache', 'glucose_apache', 'heart_rate_apache', 'map_apache',\n",
        "                                                                'resprate_apache', 'temp_apache', 'd1_diasbp_max', 'd1_diasbp_min',\n",
        "                                                                'd1_heartrate_max', 'd1_heartrate_min', 'd1_mbp_max', 'd1_mbp_min',\n",
        "                                                                'd1_spo2_max', 'd1_spo2_min', 'd1_sysbp_max', 'd1_sysbp_min',\n",
        "                                                                'd1_temp_max', 'd1_temp_min', 'd1_glucose_max', 'd1_glucose_min']])\n",
        "scaled_data_df = pd.DataFrame(scaled_data, columns=['age', 'bmi', 'height', 'weight', 'gcs_eyes_apache', 'gcs_motor_apache',\n",
        "                                                    'gcs_verbal_apache', 'glucose_apache', 'heart_rate_apache', 'map_apache',\n",
        "                                                    'resprate_apache', 'temp_apache', 'd1_diasbp_max', 'd1_diasbp_min',\n",
        "                                                    'd1_heartrate_max', 'd1_heartrate_min', 'd1_mbp_max', 'd1_mbp_min',\n",
        "                                                    'd1_spo2_max', 'd1_spo2_min', 'd1_sysbp_max', 'd1_sysbp_min',\n",
        "                                                    'd1_temp_max', 'd1_temp_min', 'd1_glucose_max', 'd1_glucose_min']).reset_index(drop=True)\n",
        "scaled_data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "UOfnrdq4BtGw",
        "outputId": "0c72ee90-7a83-400f-baf8-c9668252df1b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ethnicity_African American</th>\n",
              "      <th>ethnicity_Asian</th>\n",
              "      <th>ethnicity_Caucasian</th>\n",
              "      <th>ethnicity_Hispanic</th>\n",
              "      <th>ethnicity_Native American</th>\n",
              "      <th>ethnicity_Other/Unknown</th>\n",
              "      <th>gender_F</th>\n",
              "      <th>gender_M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38181</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38182</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38183</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38184</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38185</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38186 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ethnicity_African American  ethnicity_Asian  ethnicity_Caucasian  \\\n",
              "0                               0                0                    1   \n",
              "1                               0                0                    1   \n",
              "2                               0                0                    1   \n",
              "3                               0                0                    1   \n",
              "4                               0                0                    1   \n",
              "...                           ...              ...                  ...   \n",
              "38181                           0                0                    1   \n",
              "38182                           0                0                    1   \n",
              "38183                           0                0                    0   \n",
              "38184                           0                1                    0   \n",
              "38185                           0                0                    1   \n",
              "\n",
              "       ethnicity_Hispanic  ethnicity_Native American  ethnicity_Other/Unknown  \\\n",
              "0                       0                          0                        0   \n",
              "1                       0                          0                        0   \n",
              "2                       0                          0                        0   \n",
              "3                       0                          0                        0   \n",
              "4                       0                          0                        0   \n",
              "...                   ...                        ...                      ...   \n",
              "38181                   0                          0                        0   \n",
              "38182                   0                          0                        0   \n",
              "38183                   0                          0                        1   \n",
              "38184                   0                          0                        0   \n",
              "38185                   0                          0                        0   \n",
              "\n",
              "       gender_F  gender_M  \n",
              "0             0         1  \n",
              "1             1         0  \n",
              "2             1         0  \n",
              "3             0         1  \n",
              "4             1         0  \n",
              "...         ...       ...  \n",
              "38181         0         1  \n",
              "38182         0         1  \n",
              "38183         1         0  \n",
              "38184         0         1  \n",
              "38185         1         0  \n",
              "\n",
              "[38186 rows x 8 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# identify categorical columns to be encoded\n",
        "ctgy_cols = []\n",
        "for i, v in clean_diabetes_df.dtypes[clean_diabetes_df.dtypes == 'object'].items():\n",
        "  ctgy_cols.append(i)\n",
        "\n",
        "dummies = pd.get_dummies(clean_diabetes_df[ctgy_cols]).astype(int).reset_index(drop=True)\n",
        "dummies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0iMk1lJwLQ_j"
      },
      "outputs": [],
      "source": [
        "# save non-transformed/scaled data to a new dataframe to remove index and improve readability\n",
        "binary_data = clean_diabetes_df[['apache_2_diagnosis', 'apache_3j_diagnosis', 'apache_post_operative',\n",
        "       'arf_apache', 'intubated_apache', 'ventilated_apache', 'aids', 'cirrhosis', 'hepatic_failure',\n",
        "       'immunosuppression', 'leukemia', 'lymphoma', 'diabetes_mellitus']].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "kS0NdbWpB1LR",
        "outputId": "52252d3d-b266-4d1c-9223-e6bce7e4c7e5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ethnicity_African American</th>\n",
              "      <th>ethnicity_Asian</th>\n",
              "      <th>ethnicity_Caucasian</th>\n",
              "      <th>ethnicity_Hispanic</th>\n",
              "      <th>ethnicity_Native American</th>\n",
              "      <th>ethnicity_Other/Unknown</th>\n",
              "      <th>gender_F</th>\n",
              "      <th>gender_M</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>...</th>\n",
              "      <th>arf_apache</th>\n",
              "      <th>intubated_apache</th>\n",
              "      <th>ventilated_apache</th>\n",
              "      <th>aids</th>\n",
              "      <th>cirrhosis</th>\n",
              "      <th>hepatic_failure</th>\n",
              "      <th>immunosuppression</th>\n",
              "      <th>leukemia</th>\n",
              "      <th>lymphoma</th>\n",
              "      <th>diabetes_mellitus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.297782</td>\n",
              "      <td>-0.793148</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.847794</td>\n",
              "      <td>-0.230513</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.092244</td>\n",
              "      <td>-0.804818</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.236669</td>\n",
              "      <td>-0.214467</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.252231</td>\n",
              "      <td>3.372639</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38181</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.358894</td>\n",
              "      <td>0.069880</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38182</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.236669</td>\n",
              "      <td>0.369629</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38183</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.153357</td>\n",
              "      <td>1.679250</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38184</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.520032</td>\n",
              "      <td>-1.273530</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38185</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.024494</td>\n",
              "      <td>-0.030827</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38186 rows × 47 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ethnicity_African American  ethnicity_Asian  ethnicity_Caucasian  \\\n",
              "0                               0                0                    1   \n",
              "1                               0                0                    1   \n",
              "2                               0                0                    1   \n",
              "3                               0                0                    1   \n",
              "4                               0                0                    1   \n",
              "...                           ...              ...                  ...   \n",
              "38181                           0                0                    1   \n",
              "38182                           0                0                    1   \n",
              "38183                           0                0                    0   \n",
              "38184                           0                1                    0   \n",
              "38185                           0                0                    1   \n",
              "\n",
              "       ethnicity_Hispanic  ethnicity_Native American  ethnicity_Other/Unknown  \\\n",
              "0                       0                          0                        0   \n",
              "1                       0                          0                        0   \n",
              "2                       0                          0                        0   \n",
              "3                       0                          0                        0   \n",
              "4                       0                          0                        0   \n",
              "...                   ...                        ...                      ...   \n",
              "38181                   0                          0                        0   \n",
              "38182                   0                          0                        0   \n",
              "38183                   0                          0                        1   \n",
              "38184                   0                          0                        0   \n",
              "38185                   0                          0                        0   \n",
              "\n",
              "       gender_F  gender_M       age       bmi  ...  arf_apache  \\\n",
              "0             0         1  0.297782 -0.793148  ...           0   \n",
              "1             1         0  0.847794 -0.230513  ...           0   \n",
              "2             1         0  1.092244 -0.804818  ...           0   \n",
              "3             0         1  0.236669 -0.214467  ...           0   \n",
              "4             1         0 -0.252231  3.372639  ...           0   \n",
              "...         ...       ...       ...       ...  ...         ...   \n",
              "38181         0         1  0.358894  0.069880  ...           0   \n",
              "38182         0         1  0.236669  0.369629  ...           0   \n",
              "38183         1         0  1.153357  1.679250  ...           0   \n",
              "38184         0         1  1.520032 -1.273530  ...           0   \n",
              "38185         1         0 -2.024494 -0.030827  ...           0   \n",
              "\n",
              "       intubated_apache  ventilated_apache  aids  cirrhosis  hepatic_failure  \\\n",
              "0                     0                  0     0          0                0   \n",
              "1                     0                  1     0          0                0   \n",
              "2                     1                  1     0          0                0   \n",
              "3                     0                  0     0          0                0   \n",
              "4                     1                  1     0          0                0   \n",
              "...                 ...                ...   ...        ...              ...   \n",
              "38181                 0                  1     0          0                0   \n",
              "38182                 1                  1     0          0                0   \n",
              "38183                 0                  0     0          0                0   \n",
              "38184                 1                  1     0          0                0   \n",
              "38185                 0                  0     0          0                0   \n",
              "\n",
              "       immunosuppression  leukemia  lymphoma  diabetes_mellitus  \n",
              "0                      0         0         0                  1  \n",
              "1                      0         0         0                  1  \n",
              "2                      0         0         0                  0  \n",
              "3                      0         0         0                  1  \n",
              "4                      0         0         0                  1  \n",
              "...                  ...       ...       ...                ...  \n",
              "38181                  0         0         0                  0  \n",
              "38182                  0         0         0                  1  \n",
              "38183                  0         0         0                  0  \n",
              "38184                  0         0         0                  0  \n",
              "38185                  0         0         0                  0  \n",
              "\n",
              "[38186 rows x 47 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# combine the transformed, scaled, and unmodified data\n",
        "final_processed_df = pd.concat([dummies, scaled_data_df, binary_data], axis = 1)\n",
        "final_processed_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mCMQuIC9Q09Q"
      },
      "outputs": [],
      "source": [
        "# split preprocessed data\n",
        "X = final_processed_df.drop(columns=['diabetes_mellitus'])\n",
        "y = final_processed_df['diabetes_mellitus']\n",
        "\n",
        "# split further into training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfP2c1xXU47A"
      },
      "source": [
        "# Chart and Analyze Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "Rxc5ZabbU4jQ",
        "outputId": "848ba308-c25d-42ec-f6c3-606acf21d66d"
      },
      "outputs": [],
      "source": [
        "# export to CSV\n",
        "clean_diabetes_df.to_csv('Resources/diabetes_cleaned.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "Z07FXfkcXPmb",
        "outputId": "10a6e0b8-3e59-4a35-ea11-4a335ec21f75"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>gender</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>apache_2_diagnosis</th>\n",
              "      <th>apache_3j_diagnosis</th>\n",
              "      <th>apache_post_operative</th>\n",
              "      <th>arf_apache</th>\n",
              "      <th>...</th>\n",
              "      <th>d1_temp_min</th>\n",
              "      <th>d1_glucose_max</th>\n",
              "      <th>d1_glucose_min</th>\n",
              "      <th>aids</th>\n",
              "      <th>cirrhosis</th>\n",
              "      <th>hepatic_failure</th>\n",
              "      <th>immunosuppression</th>\n",
              "      <th>leukemia</th>\n",
              "      <th>lymphoma</th>\n",
              "      <th>diabetes_mellitus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>68.0</td>\n",
              "      <td>22.732803</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>M</td>\n",
              "      <td>180.3</td>\n",
              "      <td>73.9</td>\n",
              "      <td>113.0</td>\n",
              "      <td>502.01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>37.2</td>\n",
              "      <td>168.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>77.0</td>\n",
              "      <td>27.421875</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>F</td>\n",
              "      <td>160.0</td>\n",
              "      <td>70.2</td>\n",
              "      <td>108.0</td>\n",
              "      <td>203.01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>35.1</td>\n",
              "      <td>145.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>81.0</td>\n",
              "      <td>22.635548</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>F</td>\n",
              "      <td>165.1</td>\n",
              "      <td>61.7</td>\n",
              "      <td>203.0</td>\n",
              "      <td>1206.03</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>34.8</td>\n",
              "      <td>185.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>67.0</td>\n",
              "      <td>27.555611</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>M</td>\n",
              "      <td>190.5</td>\n",
              "      <td>100.0</td>\n",
              "      <td>301.0</td>\n",
              "      <td>403.01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>36.6</td>\n",
              "      <td>156.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>59.0</td>\n",
              "      <td>57.451002</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>F</td>\n",
              "      <td>165.1</td>\n",
              "      <td>156.6</td>\n",
              "      <td>108.0</td>\n",
              "      <td>203.01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>35.0</td>\n",
              "      <td>197.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 42 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    age        bmi  ethnicity gender  height  weight  apache_2_diagnosis  \\\n",
              "0  68.0  22.732803  Caucasian      M   180.3    73.9               113.0   \n",
              "1  77.0  27.421875  Caucasian      F   160.0    70.2               108.0   \n",
              "3  81.0  22.635548  Caucasian      F   165.1    61.7               203.0   \n",
              "5  67.0  27.555611  Caucasian      M   190.5   100.0               301.0   \n",
              "6  59.0  57.451002  Caucasian      F   165.1   156.6               108.0   \n",
              "\n",
              "   apache_3j_diagnosis  apache_post_operative  arf_apache  ...  d1_temp_min  \\\n",
              "0               502.01                      0           0  ...         37.2   \n",
              "1               203.01                      0           0  ...         35.1   \n",
              "3              1206.03                      1           0  ...         34.8   \n",
              "5               403.01                      0           0  ...         36.6   \n",
              "6               203.01                      0           0  ...         35.0   \n",
              "\n",
              "   d1_glucose_max  d1_glucose_min  aids  cirrhosis  hepatic_failure  \\\n",
              "0           168.0           109.0     0          0                0   \n",
              "1           145.0           128.0     0          0                0   \n",
              "3           185.0            88.0     0          0                0   \n",
              "5           156.0           125.0     0          0                0   \n",
              "6           197.0           129.0     0          0                0   \n",
              "\n",
              "   immunosuppression  leukemia  lymphoma  diabetes_mellitus  \n",
              "0                  0         0         0                  1  \n",
              "1                  0         0         0                  1  \n",
              "3                  0         0         0                  0  \n",
              "5                  0         0         0                  1  \n",
              "6                  0         0         0                  1  \n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_diabetes_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "ww2SPR6YaNdE",
        "outputId": "fa086fc4-3806-4baf-a6ff-aff60e01a07c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "gender\n",
              "M    20895\n",
              "F    17291\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_diabetes_df['gender'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "rrfl1Iw7LxI2",
        "outputId": "86fad9e7-077f-47c6-80f4-4dc8f66902b6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAt2klEQVR4nO3dd3hUVcIG8PfOTMpk0nuAEEoILSAGECx0NEhRQMSyioh11V2VXffTXXWXta3rrmVRERWwiw0bICAI0lsoCSSEEAgkpJBJSM9Mptzvj9GBSE0ymTP33vf3PPOEqbxDmXfOLedIsizLICIiAqATHYCIiHwHS4GIiNxYCkRE5MZSICIiN5YCERG5sRSIiMiNpUBERG4sBSIicmMpEBGRG0uBiIjcWApEROTGUiAiIjeWAhERubEUiIjIjaVARERuLAUiInJjKRARkRtLgYiI3FgKRETkxlIgIiI3lgIREbmxFIiIyI2lQEREbiwFIiJyYykQEZEbS4GIiNxYCiREQUEBJEnCnj17REchotOwFOiizZw5E5Ik4f777z/jvgceeACSJGHmzJneD0ZEHsNSoBZJTEzE4sWL0djY6L7NYrHg008/RefOnQUmIyJPYClQi6SlpaFz585YsmSJ+7YlS5YgMTERl156qfu2FStW4KqrrkJ4eDiioqIwceJE5Ofnn/e1s7OzMX78eAQHByMuLg633347zGZzu70XIjoTS4Fa7M4778SiRYvc1xcuXIhZs2Y1e0x9fT1mz56NHTt2YM2aNdDpdJgyZQqcTudZX7OkpAQjRozAgAEDsHPnTqxYsQJlZWWYPn16u74XImrOIDoAKc/tt9+OJ554wr2zeNOmTVi8eDHWrVvnfswNN9zQ7DkLFixAbGwssrOzkZqaesZrzps3D2lpaXj++efdty1cuBCJiYk4ePAgUlJS2u39ENEpLAVqsejoaEyYMAHvv/8+ZFnGhAkTEB0d3ewx+fn5eOqpp7B161aYzWb3COHYsWNnLYWMjAysXbsWwcHBZ9yXn5/PUiDyEpYCtcqsWbPw0EMPAQDeeOONM+6fNGkSEhMT8c4776BDhw5wOp1ITU1FU1PTWV/P6XRi0qRJePHFF8+4LyEhwbPhieicWArUKuPGjXN/wKenpze7r6KiAjk5OZg/fz6GDRsGANi4ceN5Xy8tLQ1fffUVunTpAoOB/yyJROGOZmoVvV6PnJwc5OTkQK/XN7svIiICUVFRePvtt3Ho0CH89NNPmD179nlf78EHH0RlZSVuueUWbN++HYcPH8aqVaswa9YsOByO9nwrRHQalgK1WmhoKEJDQ8+4XafTYfHixcjIyEBqaioeffRRvPTSS+d9rQ4dOmDTpk1wOBxIT09HamoqHn74YYSFhUGn4z9TIm+RZFmWRYcgIiLfwK9gRETkxlIgIiI3lgIREbmxFIiIyI2lQEREbiwFIiJyYykQEZEb5xMg1XE4ZZjrrCivdV1qLDY0NjnQaHOgockByy8/G20OWJockAHodRL0kgS9/pefOtfFoJMQHGBAWJAfwox+CDW6fp5+8dPzuxWpB0uBFOdEjQVHKxtQYK7HscoGHK9qdBdAea0VJxua4PTSKZmSBEQHB6BjuBEdI4zoFG5Eh3Cj+3piZBCCA/jfjJSDZzSTz6qosyKzqBo5pTU4dKIO+SfqcLi8HrVWu+hoLdIx3Iie8SHoGR+CXr/87B4TzBEG+SSWAvmEGosNWUXV2FtUhayiamQWVeN4VeOFn6hQfnoJ3aKD0bdDKNKSIjCoSwRSYkOg00mio5HGsRRICHOdFZvzK7D5kBnbj1TiSEU9tP4vMTTQ4CqIpAgMTIrEgMRwGP31F34ikQexFMgr6qx2bDtcgU2HKrA534zcslrNl8CF+OklDEgMx/AeMRieEoP+ncIgSRxJUPtiKVC7OVbRgBX7S7Bqfxn2FFbB7q29vyoVZfLHiJQYjOkdh+Ep0QgJ9BMdiVSIpUAedaC0Biv2lWLl/jLklNSIjqNafnoJl3WNxIR+HTC+XzzCg/xFRyKVYClQm2UX1+C7vcVYub8UR8z1ouNojp9ewvAeMbhuQAdc3ScOQf48BJZaj6VArVLV0IRvdh/HFxlF2F/MEYGvMPrpMaZ3LK4f0BEjUmLgb+Bhr9QyLAW6aE6njJ/zyvHlziL8mFOGJrtTdCQ6j+hgf9w4KBG3XtYZiZFBouOQQrAU6IJO1Fjw4daj+GJnEUprLKLjUAvpJGBESgxuG5qEUT1jeS4EnRdLgc5pf3E1Fmw4gqWZJWhycFSgBh3Djbh1SGdMH5SImJAA0XHIB7EUqBlZlrE65wQWbDyMrYcrRcehduJv0OGGtE74/Yju6BzFTUt0CkuBAABWuwOf7yjEwk0FPIJIQ/Q6CRP6JeCBUd3RKz5UdBzyASwFjWuyO/HZjmN4Y20+9xdomCQBo3vG4oFRyRiYFCE6DgnEUtAom8OJL3YW4Y21h1Q98Ry13NBukXgsvRfLQaNYChrjcMr4alcR5v6Uh8JKlgGdW3rfOPxlXC90jwkWHYW8iKWgIav2l+KFHw5wnwFdNL1OwvRBiXh0bA/EhgaKjkNewFLQgINltXhmaTY25JlFRyGFMvrpcddVXXHfiG6ciE/lWAoqVt1gw8s/5uLjbcc4Qyl5RJTJH49f2ws3DkoUHYXaCUtBhRxOGR9vO4pXfjyIkw020XFIhS7rEolnp6QiJS5EdBTyMJaCyuw+dhJPLMnCgdJa0VFI5fz0EmZd1RWPjEnhCnEqwlJQiXqrHS+tzMUHWwrALUXkTR3Djfj7pD64pm+86CjkASwFFfj5YDn+uiSL5xuQUNf0icPzU/shOphzKikZS0HBaiw2PLs0G5/vLBIdhQiAa0f0C1P7cdSgYCwFhdqQV46/fJmJkmpOTUG+Z9rATvj7pD48fFWBWAoKY3M48Z+VuXh7w2Hwb458WcdwI/47/RIM7RYlOgq1AEtBQQorG/CHT3djT2GV6ChEF0WSgLuu7IrHxvVEgIFHKCkBS0EhlmYW44klWai12EVHIWqxSzqF4Y3fpaFTBNdu8HUsBR9nsTnwj+/2Y/GOQtFRiNokIsgPr9w0ACN7xoqOQufBUvBhBeZ63PvhThwsqxMdhcgjdBLw0OgeeGRMD64V7aNYCj5qY54ZD36yC9WNnKaC1GdYj2j87+ZLEWHyFx2FfoOl4IMWbjyC55bnwMFTk0nFOoQF4q3bB6J/p3DRUeg0LAUf0mR34m9fZ+GLDJ6MRtoQ6KfDy9MHYHy/BNFR6BcsBR9RXmvF/R9lIOPoSdFRiLxKkoA/X9MTD45KFh2FwFLwCQfLajFz4XYU8+xk0rBpAzvhhan94KfXiY6iaSwFwXYWVOKu93dyhzIRXDug5902EMEBBtFRNIulINCanDI8+MkuWGxO0VGIfEbvhFC8d+dgxHFNaCFYCoJ8mVGEx7/K5DKZRGfROTIIH989BImRPAPa21gKAsz/OR//WnGAE9oRnUdCWCA+uWcoukabREfRFJaCl72wPAfz1x8WHYNIEWJCAvDx3UO4FrQXsRS86Nml2Xh34xHRMYgUJSLIDx/eNQSpHcNER9EEHvvlJS/8kMNCIGqFkw023PrOVuw6xnN4vIGl4AX/XnEA83/mJiOi1qqx2HH7u9uQcbRSdBTVYym0s5dX5eLNdfmiYxApXn2TA3cu2oHs4hrRUVSNpdCOXludh//9dEh0DCLVqLHYMWPhdhwx14uOoloshXby9vp8vLL6oOgYRKpjrrPitne3oaS6UXQUVWIptINv9xzHCz8cEB2DSLWOVzXitne3oaLOKjqK6rAUPGxzvhmPfZHJE9OI2ll+eT3uWLQdtRbOG+ZJLAUPyi2txX0fZqDJwbmMiLxh3/Ea3PdhBuz8P+cxLAUPKaluxMxF21FrsYuOQqQpm/Mr8NS3+0XHUA2WggfUWGyYuXAHSrgeApEQn24/hgU8OdQjWApt5HDKePDjXcgtqxUdhUjTnluWjbUHToiOoXgshTb698oD2JBnFh2DSPOcMvCHT3cjt5Rf0NqCE+K1wbLMEjz4yS7RMRSvauPHqN70abPbdKZwJD700RmPrVjxOur2rkDE6HsQOvj6c75m6SePw1q474zbjd0GIfbGfwAA6vavRdXP70O2WRDc/xpEjJrlfpy9ugxlnz2FhDtehS6Ac/orSacII7598EpEBQeIjqJIXPOulQ6W1eIvX+4VHUM1/KI7I+6m507doDtzENtwcAusJbnQB0de8PVipvwNcJza6e9orEHJoj8gqNdVrusN1ahcMRdR4x+BITweJ76cg4DO/RDUfTAAoGLlm4gYMZOFoEBFJxvx+4934dN7hkKvk0THURxuPmqFGosN932Ygfomh+go6qHTQx8cceoS1HyaZHutGZU/voXoiX8GdBf+LqM3hjR7PUvBHkh+AQjq6SoFe1UppIAgmHoPR0BCCgI794fNfAwAUJ+9DpLegKCeV3j+fZJXbD9Sif+uyhUdQ5FYCi0kyzIeWbyHc694mP1kMYremIGit+5C+bcvwlZV6r5Plp0wL30ZoUOmwj8mqVWvX5e5Cqbew6Hzd637a4jsCNlmRVNZPhyNtWgqOQj/mC5wNNaiasPHiLz6fo+8LxJn3s/5WJfLHc8txVJoobk/HcJPPMLBowISeiJqwmzETv8nosb9AY76kyj96M9wNLpmw6zZ+iUknR4hA69r1etbi3NhMx9FcP9r3LfpA4MRPeFRmJe+jNIPZsOUOhrGbgNxcu0ChAycCHt1GYoX/RHFCx5A/YGNHnmf5F2yDMz+fC9Keah4i3CfQgtkHD2J19bkiY6hOsbug05diQECOvTC8bfvRn3WGgR07oeajO+QcMdrkKTWbR+uy/wRftFJCOjQs9ntQSlXICjl1CYiy7FM2MqPIvLq+1H89r2InvQY9KYIlHwwG4GJqdCbwlv1+5M4lfVN+MOnrv0LBj2/A18MlsJFqrPa8ehne+Bw8mCt9qbzD4R/dBfYThYDkg7O+mocn3fnqQfITpxcuwA1O79Fp98vPO9rOW0W1OesR/iw3533cbLdhspV8xA18U+wnyyB7HQgsHM/AIBfZEdYS3IRlDykze+NvG9HwUn8Z9VBPH5tL9FRFIGlcJH+/u1+HKtsEB1DE2S7DbaKQgQk9oUpdRQCu1zS7P4Tnz8NU9/RCO439oKv1XBgI2SHDaa+o877uKrNixHYbSAC4pPRVJYPOE8dRCA77YCTc+so2fz1+RjaLRIje8aKjuLzWAoXYVlmCb7aVSQ6hmqd/GkBjMmXQR8aA2dDNao3L4azqQHBqWOgN4ZCbwxt/gSdAXpTBPyiOrlvMi/9L/QhUYgYMbPZQ+syVyGox9AzX+M0TeVH0XBgPRJmzgUAGCI7AZIOtXtXQR8cAVtFEfwTenjs/ZL3yTLwf19lYtWjIxBm9BMdx6exFC6gpLoRf/06S3QMVbPXmmH+/iU4GmqgDwpFQIdeiL/9vzCEXfy3OntNOSA132ZsqzwOa1E2Yqc/c87nybKMypWvI2L0Pe4jk3R+AYga/wgqf5wH2WFD5NX3wxAS3bo3Rz6jrMaKOd/vx8vTB4iO4tN4RvN5yLKMW9/Zhi2HK0RHISIPeXfGIIztEyc6hs/i7vjz+GDLURYCkcr89essVDU0iY7hs1gK53C8qhH/XsElNYnU5kStFf/4jusvnAtL4Rye/DqL01gQqdQ3e4qxcn/phR+oQSyFs/hubzHW5paLjkFE7ejJb/ahzsqVEn+LpfAb1Y02/PP7bNExiKidldda8eqPB0XH8Dkshd94aeUBmOusomMQkRe8t7kAeVw1sRmWwmn2FFbhk23HRMcgIi+xO2U8/S13Op+OpXCaf36/H5zaiEhbthyuwPd7i0XH8BkshV8syyzBrmNVomMQkQDPLctBQxN3OgMsBQBAk92JF3lOApFmldZY8L81h0TH8AksBQDvby7gDKhEGrdw0xEcr2oUHUM4zZdCVUMT5v7EhXOItK7J7sRrq3mIquZL4bU1eaixcFsiEQFf7TqO/PI60TGE0nQpHK2ox0dbj4qOQUQ+wuGU8fIqbY8WNF0Kc386BJuDx6AS0SnL95Vg3/Fq0TGE0WwpFFY24Jvdx0XHICIfI8vASytzRccQRrOl8Oa6Q7DzTDUiOoufD5Zjm0bXUtFkKRRXNeKrDI4SiOjcXlujzaMSNVkK89blo8nhFB2DiHzY5vwK7C2sEh3D6zRXCmU1Fny2s1B0DCJSgHnr8kVH8DrNlcLb6w+jyc5RAhFd2KrsUs2dt6CpUqiz2vHZDo4SiOjiOGVgwcYjomN4laZK4cudhVx+j4haZMmuIlTWN4mO4TWaKQVZlvHBFp69TEQtY7E58aGGPjs0Uwrr88w4bK4XHYOIFOijbUdh18gRi5ophfc3F4iOQEQKVV5rxeqcE6JjeIUmSuFYRQPW5WrjL5SI2sfiHdpYv10TpfDBlgKuvUxEbbL+YLkmFuFRfSk02Z34aleR6BhEpHBOGfhcA4e0q74U1uaewMkGm+gYRKQCX+wshFPlmx1UXwqcHpuIPKW42oKfD5aLjtGuVF0K1Y02rDnAHcxE5Dlq3+Gs6lJYllnCeY6IyKPW5paj1qLeTdKqLoWvd3MHMxF5VpPdiR+zy0THaDeqLYXCygbsPHpSdAwiUqHlWSWiI7Qb1ZbCt3uOQ1b3QQJEJMj6PDNqVLoJSbWlsErFwzsiEqvJ7sRqlX7GqLIUymosyDpeLToGEanYskx1bkJSZSmsyTnBTUdE1K42qHQTkipLYXWOOod1ROQ7mhxOrFXheVCqK4XGJgc2HTKLjkFEGrAhT32fNaorhfV55bDyhDUi8oINeeqb8kJ1paDWIwKIyPeU1ViRW1orOoZHqa4U1quwuYnId6lttKCqUigw16Osxio6BhFpiNpmTVVVKWw/Uik6AhFpzI6CSlhsDtExPEZVpbD1SIXoCESkMRabEzsK1POFVFWlsO2wev5iiEg5dqhoK4VqSqHoZIMmFtUmIt+zu7BKdASPUU0pcH8CEYmyp7AKskrm1mEpEBG1Ua3FjkMn6kTH8AjVlMIeFQ3fiEh5dh+rEh3BI1RRCla7A/nl6mhpIlKm3YXqWOlRFaWQV1YHm0Md2/OISJk4UvAh+4u5oA4RiZV3og4NTXbRMdpMFaWQXVwjOgIRaZzDKatiZ7MqSmE/S4GIfABLwQfIsowDKpu6loiUKY+lIN7RigbUWZW/HY+IlC+vjKUg3GGz8v8SiEgd1HBovOJLocDcIDoCEREA4FhlA6x2ZU+jrfxSqKgXHYGICIDrCKTD5cr+TFJBKXCkQES+g6UgWFElS4GIfEdJtbKn8Fd0KciyzDUUiMinlFZbREdoE0WXQnmtFVa7U3QMIiK30hqWgjAcJRCRr+FIQaCKuibREYiImilhKYhTWc9SICLfcqLWouilOZVdCg0sBSLyLTaHDLOCt2IouxQ4UiAiH1ReaxUdodVYCkREHqbkSTpZCkREHlZntYmO0GosBSIiD6u1cKQgRHWjctuYiNSLm48EsdqUPUUtEalTHUcKYjQ5OMUFEfkejhQEaeK8R0Tkg7hPQRCOFIjIF1kUvGlb0aVgcyj3VHIiUi8np7nwPodThsOp3D94IlIvJW/EUGwp2JT8p05EqqbkCfEMogO0lp2jBPKAviH1uCc2F1fJO2GymkXHIZVoCrkGwADRMVpFsaXgp5dERyCFujbGjNvC9+PSxi0wmrMgHecXDPIsY+IA0RFaTbGl4K9X7JYv8jKj3oHbE4ow2ZiJlKoNMNQWAbWiU5Gq6fSiE7SaYktBkiT463U8LJXOqmOgFfcm5GOsLgMdzJsgmWtERyItYSmIEWBgKdApg8JqcVdMNi63b0fYiZ2QSjg3FgmiU+5Hq3KTA/A36ADlrmVBbSRJMm6ILcNNofvQr34TAitzgSLRqYjAUhDF38D9CloTYrDj7g7HMCFgN7pWboS+ugyoFp2K6DdYCmKwFLShe1Aj7o3Pw0jsRGz5Fkgn6kVHIjq/wDDRCVpN0aVg9FPuzhw6vxGRJ3FHVDYus26FqXw3pGLuOyIFCY4VnaDVFF0KkSZ/0RHIQ/x0Mm6JL8ENpr3oXbsJ/lWHgQbRqYhaycRSEIKloGwx/jbcnXAE6X670LliE3SVFUCl6FREHhAcIzpBqym6FKJYCorz67QSw5w7EHliK6QyHj5GKsSRghiRpgDREegijI8x47bwfRjQuAVG8z5OK0Hqx30KYkQGc6Tgi4x6B+5IKML1xr3oUbWR00qQtgSEAQblfmFVdClw85HvaD6txEZIZrYAaZSC9ycACi8F7mgW67LwGsyKzsHltm0ILd8JqUS569ISeYyC9ycACi+FuNBA0RE0RZJkTIsrw00hWUit38xpJYjOhiMFcTqGG6GTAK63036aTyuxAfqqE0CV6FREPowjBXH8DTokhBlxvKpRdBRV6R7UiPviD2KEe1oJnkVGdNEUfOQRoPBSAICkqCCWggeMiqzEjKhsDLZu47QSRG1h4uYjoTpHBmFzfoXoGIrjp5Nxa3wxbjBlonfNJvhVc1oJIo+I7Co6QZsovxSigkRHUIwYfxvu6XAE6YZdSKzYCF1lJaeVIPK0uH6iE7SJ4kshKdIkOoJP6xdSj7tjD+Aq5w5EntgGqZTTShC1m+A4wBQlOkWbKL4UOkdypPBbE2LM+N0v00oEmbOA46ITEWlEXF/RCdpM8aXQPdak+cNSjXoHZnYowvWBe5BctRGG2uOcVoJIhLhU0QnaTPGlEORvQJdoEw6Xa2s1rk6BVtybcAhjdBnoYN4EqZwtQCQcS8E39O0QpolS4LQSRD6Om498Q98Oofh+b7HoGB7nnlYidB/61W5CwElOK0Hks3R+QExP0SnaTDWloBacVoJIoaJTAL2f6BRtppJSCBMdoU16mBpxTxynlSBSNBVsOgJUUgqRJn8khAWipNoiOspF47QSRCrDUvAtfTuE+nQpnJpWYi9612zmtBJEahOv/COPABWVQlpSBFbnnBAdoxnXtBKHkW7YzWkliNROBYejAioqhSFdfePUck4rQaRBEV2BkHjRKTxCNaXQv1MYgvz1aGhyeP33nhhjxq3h+3Bpw2YYK/ZxWgkirek+WnQCj1FNKfjpdRiYFIENeeZ2/71c00oU4vrAvZxWgohYCr5qSNfIdiuFX6eVGKvLQAKnlSCiX+kMQNfholN4jLpKoZtn9ysMCa/BrOhsDLVtQ2h5BqeVIKIzdRwEBKrnBFpVlcIlncIR6KeDxda6Y/4lScaNcWW4KSQLqXWbOa0EEV2YijYdASorBX+DDoOSIrHx0MVvQgrzs+OuhKMYH7CH00oQUcuxFHzbyJ4xFyyFHqZG3BN/ECPlHYgp38ppJYiodQLDgY5polN4lOpKYVSvWDy7LOeM20dHVWJGZDYGWbbCZN4D6TinlSCiNuo6HNDpRafwKNWVQveYYHSNNqGosg63xh/HDaZM9K7ZBL/qI4D6l1wgIm9S2aYjQIWlAADvDzqKTlv/Dl3lSU4rQUTtJ3mM6AQepxMdoD107poCneWk6BhEpGZRyUB4Z9EpPE6VpYDEIUBwnOgURKRmyVeLTtAu1FkKOh3Qa4LoFESkZv2ni07QLtRZCgDQ+zrRCYhIrWJ6qe5Q1F+ptxS6DAOMEaJTEJEaXXKL6ATtRr2loDcAPbkJiYg8TNID/W8SnaLdqLcUAODS20QnICK16TYSCE0QnaLdqLsUki4HYvuITkFEajLgVtEJ2pW6SwEABt4pOgERqUVAmOqPbFR/KVxyM+BnEp2CiNSg72TAzyg6RbtSfykEhgKpU0WnICI1UPmmI0ALpQAAg2aJTkBEShfZDeg8VHSKdqeNUuiYBiQMEJ2CiJRMxecmnE4bpQBwtEBErSfpVH1uwum0Uwr9prmOHCAiaqleE4GIJNEpvEI7peBvUu0EVkTUzob9SXQCr9FOKQDchERELdd9DNBhgOgUXqOtUojrA3S+XHQKIlISDY0SAK2VAgBc+YjoBESkFIlDgS5Xik7hVdorhZ7jgE6DRacgIiUYNlt0Aq/TXikAwKi/iU5ARL4urh+Qki46hddpsxS6jwKSrhKdgoh82bBHRScQQpulAACjOVogonOI7A70mSI6hRDaLYWkK4Buo0SnICJfdNUjgE6bH4/afNe/Gv2U6ARE5GtCOwL9bxadQhhtl0KngUDKtaJTEJEvufJhwOAvOoUw2i4FABj1VwCS6BRE5Auie2p+5gOWQkJ/oM91olMQkS+49kVA7yc6hVAsBQAY+VfX1LhEpF29J7kOV9c4fhICQGwvzcyVTkRnYTAC6c+LTuETWAq/uvoZIDBcdAoiEuHKh4HwzqJT+ASWwq+CY4BrnhGdgoi8Layz67wEAsBSaC5tBtBlmOgURORN6c8BfkbRKXwGS+G3Jr4K6ANEpyAib+g2kkcf/gZL4beik4Hhfxadgojam84PuPbfolP4HJbC2Vz5CBDTS3QKImpPQ+4DYnqKTuFzWApnY/AHJr0GnulMpFKmWGDE/4lO4ZNYCufSeSgwcKboFETUHq6bCwSGik7hk1gK53P1HCA4XnQKIvKkwfe4luWls2IpnE9gmGsuFFKlFzZYIc2pwSMrLO7bZn7TCGlOTbPL0Hfrz/s6S3JsGPR2HcL/VQPT8zUY8FYdPtzb1OwxH2fakPhKLSJfrMFjqyzN7iuociJlbh1qrLLn3hydXUxv4JpnRafwaQbRAXxe38lA1kTgwFLRSciDdhx34O1dTegfd+b3onHJeiy6/tRx6/768+9bijRK+NuwAPSK1sFfL2HpQRvu/NaCWJMO6ckGmBucuPv7Rrx3vRHdInSY8EkDRnbRY0KKa+K13y9rxL/GBiA0gPuw2pUhEJi2APALFJ3Ep3GkcDGumwuEJYpOQR5S1yTjd0sa8c4kIyICz/wgDtBLiA/WuS+RxvN/WI/sYsCU3n7oHaNH90gdHh4agP5xOmw8ZgcAHD4pIyxAwk2pfhjcUY9RXfXILncCAD7JssFfL2Fqb23PzOkVY+cAcX1Fp/B5LIWLERQJ3Pg+oNfuwhtq8uByCyb0MGBst7MPlNcV2BH7Ui1S5tbhnu8acaLeedGvLcsy1hy2I7fCieFJrtfvEalDg03G7hIHKhtl7DjuQP84PSobZTy91oLXr+U313bX4xpg6P2iUygCNx9drE4DXdsif/iL6CTUBov32bCrxIEd95jOev+1yQbc2MeApHAdjpx04qm1Vox+vwEZ95oQYDj3iKHaIqPjy7WwOgC9BLw5IRBXd3f994owSnh/shEzvmlEo03GjEv8kJ5swKxvG/GHy/xxpMqJ6xY3wOYA/jEyANP6cNTgUaZY4Po3RadQDJZCSwy5Dzi2Bdj/tegk1AqF1U48vMKCVbcFIfAcH/A3pZ76QE6N1WNQBz2SXq3Dsjz7eTfxhAQAe+4PRl2Ta6Qwe6UF3SJ0GNnF9V9sSm8/TDnt+esK7Mg64cDr4wOR/L86fHqDEfHBEi57tx7Dk/SINXEQ7xkSMPlN14SXdFFYCi113VygdB9QkSc6CbVQRokDJ+plDHz71NFEDhlYf9SB17c3wfpkCPS65mWREKJDUrgOeRXn34SkkyQkR7qeOyBejxyzEy9stLpL4XRWu4wHllnw0VQjDlU6YXcCI355XEqUDtuKHJjUk6XgEUPuB3pcLTqForAUWiogBJj+AfDuGMDWIDoNtcCYrgZk/b75ZqM7v21Er2g9/u9K/zMKAQAqGpworHYiIaRlRwbJMmC1n/2+Z9ZbcW2yAWkJeuwuccDuPHUoqs3hKirygLhU17lG1CIshdaI6wNMeBn4hjuulCQkQEJqrL7ZbSY/CVFG1+11TTL+sc6KG3obkBCiQ0GVE39dY0V0kIQpvU5t+pnxdSM6hkh4YaxrB/ELG6wY1MF15FGTQ8byPDs+yLRh3oQzdyDvP+HAZ/vt2HOfq5x6ReugkyQs2NWE+GAJB8xODO6gP+N51EJ+JuCGBYCBMx63FEuhtQbcAhzbDOz6QHQS8hC9BGSdcOCDvTZUWWQkhEgY1cWAz6YZEXLaOQTHqp3Qnbamd71NxgPLLSiqccJoAHpF6/HRFGOz/ROA68ike5da8Ep6AEz+rtcz+kl4b3IgHlxugdUOvD4+EB1DuemobSRg6tuuZXapxSRZljlYbS2bBVgwFijNEp2EiH415mlg2J9Ep1AsfiVpC79A1/6FgDDRSYgIAPrfxEJoI5ZCW0V2A6a/xxPbiETrdJnr6EBqE5aCJ3QfDUyeB0j84yQSIqwzcPMn3LHsAfwU85R+04BxnFGVyOuMEcBtX/EENQ9hKXjSkHuB4ZwGg8hrDIHALYuBmBTRSVSDpeBpo/8GDJolOgWR+kk6YOo7rlUSyWNYCu1h/H+BPteLTkGkbuNeBPpcJzqF6rAU2oNOB0x9F+g6QnQSInW66lHX5lryOJZCezH4Azd/DCQMEJ2ESF2uehQY+w/RKVSLZzS3t7pyYGE6UJkvOgmR8o18Ahj5uOgUqsaRQnsLjgFu/xoI7Sg6CZGyjfk7C8ELOFLwlqpjwIdTgIpDopMQKU/6C8DlD4hOoQksBW+qNwMf3QCU7BGdhEghJGDCf4DBd4sOohksBW+z1gKLfwcc+Vl0EiLfJumASf8D0m4XnURTWAoi2K3AV3cDOd+JTkLkmyQ9MOUtoP900Uk0h6UgitMJLJsNZCwSnYTIt+j8gBveBfpOFp1Ek1gKov30LLD+JdEpiHyDPgC48T2g13jRSTSLpeALtr4FrHgcAP8qSMOC44GbPgISB4tOomksBV+R+QXwze8Bp010EiLv6zjIVQihCaKTaB5LwZfkrQa+nAVYq0UnIfKeAbcBE1/mAjk+gqXgayrygc/vAMqyRCchal86A5D+PDDkPtFJ6DQsBV9kswDL/wzs/lB0EqL2YYwEpr8PdB0uOgn9BkvBl+3+GFj2J8DeKDoJkefE9XPNIByRJDoJnQVLwdeV7Qc+n8E5k0gd+kwGJr8J+JtEJ6FzYCkogbUW+PYhIPsb0UmIWkfSAaP+Bgz/s+gkdAEsBSXZ+haw6kketkrKEpYIXP860G2k6CR0EVgKSlO4A/hiJlBTJDoJ0YWlzXAdYRQQIjoJXSSWghI1VALfPAAc/EF0EqKzC+3omuG0x1jRSaiFWApKlvk58MP/AY2VopMQnXLJrcC1/wICw0QnoVZgKShdvRlY/hiwf4noJKR1wfHApNeAnuNEJ6E2YCmoxYFlwNLZQF2p6CSkRf2mA+P/DRgjRCehNmIpqEljFbBmDpDxHiA7RachLTDFABNfAXpPEp2EPISloEZFGcCyR4GSvaKTkFpJOte+g6v/CZiiRKchD2IpqJXTCex417WID2ddJU/qPsZVBvGpopNQO2ApqF1tGfDj00DW59ykRG0T1w+45p9A99Gik1A7YiloxYkcYO3zQM734Apv1CKhHYHRTwL9bwZ0OtFpqJ2xFLSmJNNVDjzxjS4kIBS46hFg6AOAn1F0GvISloJWFWUAa58F8n8SnYR8jc4ADLwTGPk4YIoWnYa8jKWgdUe3AGufAwo2iE5Cokk6oNdEYMzfgehk0WlIEJYCuRz+2VUOhdtEJyFv8w8GBvzOtSxmVHfRaUgwlgI1l/cjsP4lloMWhCUCl93rmsnUGC46DfkIlgKdXek+IGORa9I9a43oNORJnQa7dh73vg7QG0SnIR/DUqDza6oHsr4Edi4ESvaITkOtJemBPtcBQx8EEgeLTkM+jKVAF694t6scsr4CbPWi09DFCAgDBs4ALrsPCE8UnYYUgKVALWepATI/c028V7ZPdBr6LYMRSLkG6DsF6JEO+AeJTkQKwlKgtincDux6H8j9AWioEJ1Gu/QBQPJYIHUqkDIOCAgWnYgUiqVAnuF0uo5Yyl3uKoiKPNGJ1E/n55qHKHUq0HM8EBgqOhGpAEuB2of50KmCKNwGyA7RidRBZwC6Dgf6TgV6T+SiNuRxLAVqfw2VwMGVrpLI/wloqhOdSFmiewJJVwBJV7pGBly/gNoRS4G8y24FjmwACtYDx3cBxXuAplrRqXyHpAPi+gJJV/1SBFdw/iHyKpYCieV0AuZc4HjGqUtZNuC0iU7mHTo/oMOAUyOBzkOBwDDRqUjDWArke2wWoDSreVFUHobi14EICAViev5y6QXE93edXcxDRsmHsBRIGRqrXMVQXQhUFQLVRa5f/3q9sVJ0QhdDIBCeBER0ASK7AhFdgegerhII6yg6HdEFsRRIHZrqXUVRVXiqLKqLXCfa2S2ufRkOq+vnr9ftp113WJu/ns7PdYhnQOhpP8N+c/2024NjXUUQkgBIkpA/AiJPYCkQAYAsnyoOvT9XGiPNYikQEZEbV+EmIiI3lgIREbmxFIiIyI2lQEREbiwFIiJyYykQaVyXLl3w6quvio5BPoKlQORFM2fOhCRJZ1wOHTokOhoRAMAgOgCR1owbNw6LFi1qdltMTIygNETNcaRA5GUBAQGIj49vdtHr9fj+++8xcOBABAYGolu3bpgzZw7sdrv7eZIkYf78+Zg4cSKCgoLQu3dvbNmyBYcOHcLIkSNhMplw+eWXIz8/3/2c/Px8XH/99YiLi0NwcDAGDx6M1atXnzdfdXU17r33XsTGxiI0NBSjR4/G3r172+3Pg3wLS4HIB6xcuRK33XYb/vjHPyI7Oxvz58/He++9h+eee67Z45555hnMmDEDe/bsQa9evXDrrbfivvvuwxNPPIGdO3cCAB566CH34+vq6jB+/HisXr0au3fvRnp6OiZNmoRjx46dNYcsy5gwYQJKS0uxfPlyZGRkIC0tDWPGjEFlpY9MOkjtSyYir7njjjtkvV4vm0wm92XatGnysGHD5Oeff77ZYz/88EM5ISHBfR2A/OSTT7qvb9myRQYgL1iwwH3bp59+KgcGBp43Q58+feS5c+e6ryclJcmvvPKKLMuyvGbNGjk0NFS2WCzNntO9e3d5/vz5LX6/pDzcp0DkZaNGjcK8efPc100mE5KTk7Fjx45mIwOHwwGLxYKGhgYEBbnWXOjfv7/7/ri4OABAv379mt1msVhQU1OD0NBQ1NfXY86cOVi6dCmKi4tht9vR2Nh4zpFCRkYG6urqEBXVfMnPxsbGZpulSL1YCkRe9msJnM7pdGLOnDmYOnXqGY8PDAx0/9rPz8/9a+mXKbrPdpvT6QQAPPbYY1i5ciX+85//IDk5GUajEdOmTUNTU9NZszmdTiQkJGDdunVn3BceHn5xb5AUjaVA5APS0tKQm5t7Rlm01YYNGzBz5kxMmTIFgGsfQ0FBwXlzlJaWwmAwoEuXLh7NQsrAUiDyAU8//TQmTpyIxMRE3HjjjdDpdMjMzERWVhaeffbZVr9ucnIylixZgkmTJkGSJDz11FPuUcTZjB07FpdffjkmT56MF198ET179kRxcTGWL1+OyZMnY9CgQa3OQsrAo4+IfEB6ejqWLl2KH3/8EYMHD8bQoUPx8ssvIykpqU2v+8orryAiIgJXXHEFJk2ahPT0dKSlpZ3z8ZIkYfny5Rg+fDhmzZqFlJQU3HzzzSgoKHDvwyB14yI7RETkxpECERG5sRSIiMiNpUBERG4sBSIicmMpEBGRG0uBiIjcWApEROTGUiAiIjeWAhERubEUiIjIjaVARERuLAUiInJjKRARkRtLgYiI3FgKRETkxlIgIiI3lgIREbmxFIiIyI2lQEREbiwFIiJyYykQEZEbS4GIiNxYCkRE5MZSICIiN5YCERG5sRSIiMiNpUBERG4sBSIicvt/IhnYP8yuw24AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "gender_counts = clean_diabetes_df['gender'].value_counts()#.plot(kind='pie', autopct='%1.1f%%')\n",
        "plt.pie(gender_counts,labels=['Male','Female'],autopct='%.1f%%');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "sBU0KMZNZHxq",
        "outputId": "8540f853-8d61-4235-ff98-a8523cdcac5a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAGFCAYAAAA2OmCIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABndUlEQVR4nO3dd3gU1f7H8fdmN5veQwohkEDoJHQUFAGlCMoFsQCCiA2kKTa86lWxAfoTxYYNBPSiwhVERKVXAemhl5AQEiCF9J5smd8fkUBMAimbzGbzfT1PHt2d2TPfDUk+e2bOnKNRFEVBCCGEEFbFTu0ChBBCCFGWBLQQQghhhSSghRBCCCskAS2EEEJYIQloIYQQwgpJQAshhBBWSAJaCCGEsEIS0EIIIYQVkoAWQgghrJAEtBBCCGGFJKCFEEIIKyQBLYQQQlghCWghhBDCCklACyGEEFZIAloIIYSwQhLQQgghhBWSgBZCCCGskAS0EEIIYYUkoIUQQggrJAEthBBCWCEJaCGEEMIKSUALIYQQVkgCWgghhLBCEtBCCCGEFZKAFkIIIayQBLQQQghhhSSghRBCCCskAS2EEEJYIQloIYQQwgpJQAshhBBWSAJaCCGEsEIS0EIIIYQVkoAWQgghrJAEtBBCCGGFJKCFEEIIKyQBLYQQQlghCWghhBDCCklACyGEEFZIAloIIYSwQhLQQgghhBWSgBZCCCGskAS0EEIIYYUkoIUQQggrJAEthBBCWCEJaCGEEMIK6dQuQIi6oigKWQVGMvKKSM8zkJ5XVPz/uQYy8orIKjCiKEqp12g0mnLbstNocHXU4e6ow93JHo+/vzyd7fF1dcDbWY+dXfmvFUKIypCAFjajwGAiNjWXc5dziUnJJeZyLvFpeaTmFpKRZyAz34DRrNy4IQvQ2mnw+jusG7k5EOrrQqivC80budLc14UgTycJcCHEdWmUf3YZhLByFzPyOZucw7nLOZxLuRrGCZn51FH+1piDzo4QHxeaNyr+CvV1pXkjF8L8XHF3tFe7PCGEFZCAFlYtq8DA4fgMIuMyiIzP4PCFDFJyitQuq9ZoNBDWyJWuzbzo2syLbiHehPq6qF2WEEIFEtDCqiRmFrDnXCr7YtPYey6NqOQcGvpPqI+Lni7NvOj2d2iHN/HAQadVuywhRC2TgBaqKjCY2BGVwsYTSeyKSSE+LV/tkqyeXmdHh8bu9Grhy4B2/kQ08ahwMJsQov6SgBZ1LjWnkE0nk1l/IomdZ1PIN5jULqle83d3oH9bfwa086dXC1/0Orl7UghbIAEt6kT05Rw2nEhi44kkDsal15vBXPWNq4OOPq0aMbC9P31b++HhJAPOhKivJKBFrTmVmMXPhy6y4UQSMZdz1S6nwbHXaugR6s3AdgHcHRGIj6uD2iUJIapAAlpYVG6hkdWHL/Hj3jgOX8hUuxzxN3uthr6t/bi/axNub+OHTiunwYWwdhLQwiIOnE9n2b44fjuSQG6RXFO2Zr6ueoZ3CmJUj2DC/NzULkcIUQEJaFFt6blFrDx0kWX74jiTlKN2OaIabgr1ZszNzbizfYAMLhPCykhAiyrbH5vG4l2xrD+RRJHRrHY5wgJ8XfXc3y2Yh3uGEODhqHY5QggkoEUVbD9zmU+3nGXvuTS1SxG1RK+1496uQUzqE0ZTH2e1yxGiQZOAFtelKArrTyTx2ZazHJFBXw2G1k7Dvzo2Zkq/FnKdWgiVSECLcpnMCmuOXGL+lmhOJ2WrXY5QiUYDd7YPYEq/MDoEeahdjhANigS0KKXIaGblwQt8sS2a2NQ8tcsRVqRf60ZMvb0lXZt5qV2KEA2CBLQAinvMy/bF88nmKBIyC9QuR1ixns19mHFnazo3laAWojZJQAu2nk5m1u8n5VYpUWkaDQzvFMS/B7fB311GfQtRGySgG7BTiVm889tJdkSlqF2KqKec9Vom923BE7c1lyUwhbAwCegGKCOviPfXn+aHvfGYZNUKYQHB3k68PLgtg8MD1S5FCJshAd2AmM0KP+yL4/11p0nPM6hdjrBBPZv78Pq/2tEmwF3tUoSo9ySgG4iDcem8/stxjl6Ue5lF7dLaaRjdI5jnBrTGy0WvdjlC1FsS0DauwGDivbWnWbTrHPIvLeqSl7M9bw8P564IOe0tRHVIQNuwyPgMnlseSbSsxSxUNLRjY94a1h5PZ+lNC1EVEtA2yGAy89HGKD7fFi2DwIRV8HNz4N37IujX2k/tUoSoNySgbczJhCyeXX6YkwlZapciRBmjugfzn7vb4eqgU7sUIayeBLSNMJkVvtgWzUcboygyyRKQwno18XLi/fs7cnNzH7VLEcKqSUDbgOjLOTy3/DCR8RlqlyJEpWg08EivUGbc2RpHe5ngRIjySEDXcz8fusBLK49SYJBes6h/wvxc+XxMF1r6y5KWQvyTBHQ9ZTSZefu3kyzeFat2KULUiItey7v3RXB3RGO1SxHCqtipXYAatm7dikajISMjQ+1SqiUlp5AxC/ZIOAubkFtkYur3h3jz1xMYZfyEECWqFdCJiYlMmzaN5s2b4+DgQHBwMEOHDmXTpk2Wrq9W9OrVi4SEBDw86t8C9IfjMxj6yZ/sOZemdilCWNQ3O88x+uu/SM6W5U6FgGqc4o6NjeWWW27B09OTN954g4iICAwGA+vWreOrr77i1KlTtVVrg7d8Xzz/+eUYRUbpZQjbFejhyJcPdSWiiafapQihqir3oCdPnoxGo2Hv3r3cd999tGrVivbt2/Pss8/y119/AfDBBx8QHh6Oi4sLwcHBTJ48mZycq2sNz5w5k06dOpVqd968eYSEhJR67ptvvqF9+/Y4ODgQGBjI1KlTS7bd6Bjnz59n6NCheHl54eLiQvv27fn999+Bsqe4U1NTGT16NE2aNMHZ2Znw8HB++OGHUrX07duXp556ihkzZuDt7U1AQAAzZ86s6revWgwmM/9ZdZQZK45IOAubl5BZwANf7uaXyItqlyKEqqoU0Glpaaxdu5YpU6bg4uJSZrunp2dxo3Z2fPzxxxw7dowlS5awefNmZsyYUaXCPv/8c6ZMmcKECRM4evQoq1evJiws7GrhNzjGlClTKCwsZPv27Rw9epR3330XV1fXco9VUFBA165dWbNmDceOHWPChAk89NBD7Nmzp9R+S5YswcXFhT179vDee+/x5ptvsmHDhiq9r6pKzi5g9Fd/8d+/4mr1OEJYkwKDmad/jGTOH6cwy2x4ooGq0inuvXv3ctNNN7Fy5UruueeeSh/kf//7H5MmTSIlJQUo7kGvWrWKyMjIkn3mzZvHvHnziI2NBSAoKIhHHnmEt99+u1rHiIiI4N577+X1118vs+/WrVvp168f6enpJR8q/umuu+6ibdu2vP/++0BxD9pkMrFjx46SfXr06MHtt9/OnDlzKlVjVUVfzmHcwr1czMivlfaFqA/ubB/AR6M74aCT+6VFw1KlHvSVLNdoNNfdb8uWLQwYMICgoCDc3NwYN24cqamp5OZWbtGG5ORkLl26xB133FHtYzz11FO8/fbb3HLLLbz++uscOXKkwrZMJhPvvPMOERER+Pj44Orqyvr164mLK91rjYiIKPU4MDCQ5OTkSr2nqjp2MZMHvtgt4SwavLXHE3l08T5yC41qlyJEnapSQLds2RKNRsPJkycr3Of8+fMMGTKEDh06sGLFCg4cOMBnn30GgMFgKD6onR3/7Lhf2Qbg5OR03Toqc4zHH3+cmJgYHnroIY4ePUq3bt345JNPym1v7ty5fPjhh8yYMYPNmzcTGRnJoEGDKCoqKrWfvb19qccajQaz2fLXhP+KSWX0V3+Rmlt0452FaAB2nk3lwQV7yMiT3wnRcFQpoL29vRk0aBCfffZZub3hjIwM9u/fj9FoZO7cudx88820atWKS5culdqvUaNGJCYmlgrpa093u7m5ERISUuFtW5U5BkBwcDBPPvkkK1eu5LnnnuPrr78ut70dO3YwbNgwxo4dS8eOHWnevDlRUVGV+ZZY3IYTSTz8zV6ypbcgRCmH4zO4/4vdJGbKbViiYajyKO758+djMpno0aMHK1asICoqipMnT/Lxxx/Ts2dPWrRogdFo5JNPPiEmJobvvvuOL774olQbffv25fLly7z33ntER0fz2Wef8ccff5TaZ+bMmcydO5ePP/6YqKgoDh48WNIDrswxpk+fzrp16zh37hwHDx5k8+bNtG3bttz3FBYWxoYNG9i1axcnT55k4sSJJCYmVvVbU2MrDlxg0n8PUCgjtYUoV1RyDvd9sYvYFFnjXNi+Kgd0aGgoBw8epF+/fjz33HN06NCBAQMGsGnTJj7//HM6derEBx98wLvvvkuHDh1YunQps2fPLtVG27ZtmT9/Pp999hkdO3Zk7969PP/886X2efjhh5k3bx7z58+nffv23H333SW92socw2QyMWXKFNq2bcudd95J69atmT9/frnv6dVXX6VLly4MGjSIvn37EhAQwPDhw6v6ramRhX+e4/mfDmOUEatCXNeF9Hzu+2I3Jy7JkqrCtslc3FZg7vrTfLL5rNplCFGvuDvq+GZ8d7qFeKtdihC1QgJaZa//cowlu8+rXYYQ9ZKTvZYvHupKn1aN1C5FCItrkItlWIu315yQcBaiBvINJiZ+t5+9Mje9sEES0Cr5YMMZFvx5Tu0yhKj3CgxmHluyj+OXMtUuRQiLkoBWwZfbovl4kzq3cQlhi7ILjDz8zV7OyehuYUMkoOvY0j3nmf2HrPglhKWl5BQxdsEeuU9a2AwJ6Dr0x9EEXl11TO0yhLBZFzPyeWjhHtJlFj5hAySg68ju6FSeXhaJ3OYsRO2KSs5hvMzdLWyABHQdOH4pkwnf7pe1nIWoI4fjM5jw3X4KjSa1SxGi2iSga9mF9DzGL9onc2sLUcd2nk3l6R8iZT1pUW9JQNei/CITE749wOXsQrVLEaJBWns8kffXn1a7DCGqRQK6Fr244ggnEmS+YCHUNH9rNH8cTVC7DCGqTAK6lizYEcPqw2WXwBRC1L3n/3eYqKRstcsQokokoGvBzrMpcq+zEFYkt8jEhO8OkFVgULsUISpNAtrC4tPymPr9QUwyMEUIq3IuJZfpP0Yi6wOJ+kIC2oIKDCae/O8B0vPkU7oQ1mjzqWQ+3HBG7TKEqBQJaAt6ccURjssi8kJYtU+2nGX98US1yxDihiSgLWTBjhh+iZRBYUJYO0WB55Yf5mxyjtqlCHFdEtAWcOB8mgwKE6IeyS40MvG7/eQXyUxjwnpJQNdQXpGR55YflkFhQtQz0Zdzefu3E2qXIUSFJKBraPbvp4hNzVO7DCFENSzdE8fmU0lqlyFEuSSga2BH1GX+u+e82mUIIWpgxk9HSc2R6XiF9ZGArqasAgMzfjqC3FIpRP2WklPIv1ceVbsMIcqQgK6mmauPk5BZoHYZQggL2HAiiRUHLqhdhhClSEBXw7rjiaw8eFHtMoQQFvTmmhMkZ8mHbmE9JKCrKDWnkJfldJgQNicz38DLP8vvtrAeEtBV9PLPR0nNLVK7DCFELdh4MplVh+TsmLAOEtBV8OvhS6w7LrdkCGHLZv56nBQZ1S2sgAR0JeUXmZj1+0m1yxBC1LKMPANz159WuwwhJKAra/7WszJqW4gGYtm+eI5fylS7DNHASUBXwoX0PL7aHqN2GUKIOmJW4I1fZRpQoS4J6EqY9ftJCo1mtcsQQtShvefSWHNEVqgT6pGAvoHd0an8flTWjhWiIZr9+ykKDLLilVCHBPR1mMwKb66R01xCNFQXM/Ll8pZQjQT0dfywN46TCVlqlyGEUNHnW6NJyMxXuwzRAElAVyAz38AHG86oXYYQQmX5BhNz/jildhmiAZKArsC8jWdIkxnDhBDAL5GXOHA+Xe0yRAMjAV2Oixn5/PcvWedZCHHVnD9koiJRtySgy/Hp5rMYTLLQsxDiqn2x6eyJSVW7DNGASED/w8WMfH46EK92GUIIK/TplrNqlyAaEJ3aBVibz7bU397zhc8fxZSVXOZ518534TNwEgCGlHjSty2iIO4YoGDv05RGw19E5+5XbpvZkWvJPb4Zw+XiU/76gDA8bxuHQ+PWJfvkHN9CxrYlKIYCXCMG4tXv0ZJtxswkkpa9SuDD87BzcLbguxWi7u2ISuHIhQwimniqXYpoACSgr3EpI5+f9l9Qu4xqC3z4QzBfnfGsKOU8ycv+g0ubWwAwpCeQuHQGrhED8Lx1DBoHFwyp8Wi0+grbLIg/ikvbPjj0b4tGZ0/mnhUkLX+Nxo99hs7NF1NeJmlrP8FnyHR0ngEk//QGDk3DcW7RHYDUdfPx6jNewlnYjE82n+Xrcd3ULkM0ABLQ1/hqewxFpvo7pafW2aPU4/y//ofOMxCH4HAAMrZ/i1OLbqV6uPaeAddts9HQF0o99rlzGnmnd1Jw/jCuHe7AmJGIxsEZl7a3AeDYNAJDShy06E7uia1otDqcW/eyxNsTwipsPJnE6cRsWge4qV2KsHFyDfpvablFLNtnO9eeFZOB3BNbcY0YgEajQVHM5MfsR+fVmKRlrxL/yRgSvn2WvDO7q9auoRDMJuwci/846byDUAyFFCVFY8rPpijhDPpGIZjys8nYsRTvAU/WxtsTQjWKUnwpTIjaJgH9t8U7z5FvQ3Pu5p35C3NBDi4d7gDAnJuJUpRP1p6fcGreFf8H3sK5VU8u/zyLgrijlW43fdsStK4+OIV0AkDr6IrvXc+QsuYDEr99FpcOt+PUvCvpWxbi1vVujJlJXFr0FJcWTib31J+18VaFqHO/HU0gNiVX7TKEjZNT3EBuoZFvbey+55wj63Fq3hWdmw8AilJ86t4p7Gbcuw8HQO/fnMKLJ8mO/APHpuE3bDNzz0/kndyG/+jZaHRXr1s7t+qFc6urp7EL4o5guHwe7wFPcumrCfgOfQGtixcJ3z6LY3AHtC6elnujQqjAZFb4fGs0794XoXYpwoZJD5riObcz8gxql2Exxszk4mvEHQeVPKd1dgc7Lfa+waX2tfcJxpR1+YZtZu5ZSebu/+H3wFvo/UIr3E8xGkhb/zneg6ZgTE9AMZtwbBqOvU8T7L2DKEw4Xf03JoQVWXnoApcyZI5uUXsafEArisK3u22s93x0A1pnD5z+HkkNoNHa4xDQEmPaxVL7GtIuoq3gFqsrMvesIHPXj/jf/wYOgS2vu2/Grh9xbN4Vh4AwUMxgvnrZQDEbS40yF6I+M5gUluyOVbsMYcMafEDvik4lLi1P7TIsRlHM5BzdiEuHO9DYaUttc79pBLknd5AduRZD+iWyDvxK/tm9uHUZUrJPypq5pG9bXPI4c89PZOz4Dp8hT6Pz8MeUk44pJx1zUdmeQ9Hl8+Sd2o7nrWMB0Hk3AY0d2YfXkxe9D0PqBfQ3CHgh6pMVBy5iqMd3fgjr1uCvQf+wN07tEiyqIDYSU9ZlXCMGlNnm3KoXPoMmk/nX/0jf9BU67yAa3fMyjk3al+xjzLoMmquf27IP/g4mIymrZpdqy+OW0XjeOqbksaIopK37FK/bn8BO7wiAnb0DPkOmk7bhcxSTAe8BT6Jz87X0WxZCNSk5hWw6mcSdHQLVLkXYII2iKPVz2iwLSMst4uZZm+r1vc9CCHX1adWIJY/2ULsMYYMa9CnulQcvSDgLIWpkR9RlLspgMVELGnRA/2hDE5MIIdRhVmC5/C0RtaDBBvT+2DTOJueoXYYQwgb8dOACZnODvVooakmDDegf9sonXiGEZVzMyGdb1I3nExCiKhpkQGcVGPj9aILaZQghbMgy+dAvLKxBBvQvhy7a1LzbQgj1bTqVREpOodplCBvSIAN65aGLN95JCCGqwGBSWCV/W4QFNbiATs4qIDI+Q+0yhBA2SC6dCUtqcAG94WQSDXdqFiFEbToUn0FSVoHaZQgb0fAC+kSS2iUIIWyUosC644lqlyFsRIMK6NxCI7uiU9UuQwhhw/44KgEtLKNBBfTW05cpMsrUnkKI2rM3No303CK1yxA2oEEF9IYT8slWCFG7TGaFLaeT1S5D2IAGE9BGk5ktp2WmHyFE7dt8SgJa1FyDCeg959LIzDeoXYYQogHYfuYyRlkpT9RQgwloGb0thKgrWQVG9p9PV7sMUc9JQAshRC3YIqe5RQ01iICOT8uTBdWFEHVKbukUNdUgAnr/+TS1SxBCNDAnE7LIKzKqXYaoxxpEQB+Qa0FCiDpmNCsy77+okQYR0PtjJaCFEHXvoHQORA3YfEBnFRg4k5StdhlCiAZIRnKLmrD5gD4Ul4FZVq8SQqjgUFwGiiyfJ6rJ5gNarj8LIdSSmW8gKjlH7TJEPdUAAlpGcAsh1COdBFFdNh3QJrNCZFyG2mUIIRowCWhRXTYd0CcTssgtMqldhhCiAZOAFtVl0wF9KE5+MYQQ6jqXkkuarA8tqsGmA/pUotxeJYRQn9zqKarDpgNaRk8KIaxBzOVctUsQ9ZBtB7R8ahVCWIFzKdJZEFVnswGdklNIep5B7TKEEEJ60KJabDagz8rpbSGElTiXIgEtqs5mAzr6sgS0EMI6xKXlYTSZ1S5D1DM2G9BxqXlqlyCEEEDx0pNxafI3SVSNzQZ0bKqcUhJCWA+5Di2qymYD+rz0oIUQViRGRnKLKrLZgJbTSUIIayIDxURV2WRAp+QUkidzcAshrIic4hZVZZMBLfPeCiGsTUpOodoliHpGAloIIepAhkycJKrIJgM6I08CWghhXTLyDSiKonYZoh6xyYBOy5VPqkII62IyK2QVGNUuQ9QjNhnQ6dKDFkJYoXS5/CaqwDYDWn4JhBBWSDoPoipsMqDT5JdACGGFZKCYqAqbDGj5JRBCWCPpQYuqsMmAltushBDWSNaoF1VhkwEtn1KFENZIxseIqrDJgM7Kl0+pQgjrk5EvAS0qzyYD2mSWyQCEENanyGhWuwRRj9hkQAshhDUyST6LKpCAFkKIOmKWqT5FFejULqA2yK+AEHWnIP4YWXtWUJQUjSknjUb3vIJzq57Xf03cUdI3L6AoJQ6dqzfuN92LW+chJdvzzx0ibcPnmHIzcG51Mz53TkOjtQfAXJhLwpJn8B/1Njp3v1p9b5Yml99EVUgPWghRI0pRAfZ+zfHu/2Sl9jdkJJL800wcmrSn8fiPce/5AGkbvyL39M7i9hQzKWvex63TYALG/h+Fl86Qc3hdyevTty7CrdPgehfOACYVe9CxsbFoNBoiIyNVq0FUjU32oKULLSylnVsu4/xO4BfvjFHvToGjK4V2ekyYUMyFKEohiqkAs6kAsyEfU1E+pqICFMWkdul1pynQ1BfIZCJwn+kgnQwZFe6+4sAuzG7OvNEnGDgGHrD0Umvi93zDv5tnkZWXxwt5mbwVrsNed4IVzRtRmPwnDxq0nL2YwLKEA7zUNxQ7wx918/4sqHF+R6BLjdvZtWsXvXv3ZsCAAaxdu7ZSrwkODiYhIQFfX98aH1/UDdsMaCEsJM+opW/u/5jUJogHYgLo/McFlIsJmLz9MYREUBDQkny3JuRoPck26MnLNGIymbHXm7B3MGKvN2KnM6DVGrGzK0KjKQQKUcyFmM0FmI0FmAz5GIvyMRTkUVSQR1FeHopSf0cT5acmk+1Y8cm5qNjzhPl4kH0htuS5UFdH/jyaTEZcDHYaDe6ODhw4cIBW/r6cPneObiFNSD8fw383/skD3SPIvRRXB+/E8pTgYIu088033zBt2jQWLFhAXFwcTZs2veFrtFotAQEBFjm+qBsS0EJcR3yBHn8u8a6DC+ObZ5PfJI/HUjpz+59ZOB7cgCMb8Lxmf0WrwxDSnqLgduS7NiPPoRE5Zg8yMzUU5N54qUGNHvR6xaYDPrugEDcHh1LPuTnqMSsKuYVFuDs58lDPLvwSeYJVkcdpG+BHj9BgNp2MJszPF3utlk837SK3qIhbwkK4tWWIOm+kGjQWaCM3N5fly5ezb98+EhMTWbx4Ma+99hoA6enpTJ06lfXr15OTk0OTJk14+eWXeeSRR4iNjSU0NJRDhw7RqVMnTCYTEyZMYPPmzSQmJtK0aVMmT57M008/XXKs8ePHk5GRwa233srcuXMpKipi1KhRzJs3D3t7ewu8G3E9NhnQcoZbWIpJsUNxcKdV0mk+curOk9oivmx0lC/vgRHZ7bhnrx0O+47D39cWNSYj+ujD6KMP4/rPtq70uv3DyHcPKu51F9iTlWnCbLr6U6tBg7FIh7FIR34V670S8Hq9CZ2DEXt7I1p7A3Zaw98BX0RJwJuuBryhKA9DYR6G/DyK8vNrP+D/kVT//J0NbeTN9AG3ljy+nJ3DwfMXeGZAb+Zv2U3vVqG0DmjE++u207yRN4093Wu3XgvR6mr+J3fZsmW0bt2a1q1bM3bsWKZNm8arr76KRqPh1Vdf5cSJE/zxxx/4+vpy9uxZ8vPL/ykym800adKE5cuX4+vry65du5gwYQKBgYE88MADJftt2bKFwMBAtmzZwtmzZxk5ciSdOnXiiSeeqPF7EddnkwEthCWZHLywK8ige+w+3mndhxlFsSgorHQ7w8o74JZbQhh/xAuPbUfAWHEvWZuWhDbt+r3uAu9m5Do0IkdxIStbQ34let3/pEGDoUiHoToB7wB6h6oF/PGYM/z211/EJiUDcD41gw5BFZ9KdXN0ILugEIBzKWl8vuUvPJwcsdNocHHQA3Am8TIrDx4np7CQdoF+pOcVMLRjOxQULmZkseF4FC0a+dCikTcxl1PrT0BboNe5cOFCxo4dC8Cdd95JTk4OmzZton///sTFxdG5c2e6desGQEhISIXt2Nvb88Ybb5Q8Dg0NZdeuXSxfvrxUQHt5efHpp5+i1Wpp06YNd911F5s2bZKArgM2GdB2ljiPJMTfiuzdufJn9c7T20gJv5N3c06UbN/pGM/OHvG07OLDlDPNCNp0HCUnt9Lt/7PXfe0QnqvXusPId/u7112oJyvDWKrXbUlVDfj0DCcCPHV0D2vJgg0z0Tp2x83/kVIBr9Ua0Px9ij78UiEHTh/BK7Qz763/lHbNmnIuMZFmfr44ubhSkJ/H0j2R3N6mBa0DGvHl1r9wc3SgfZA/eUXF0/h2D22Cl4sTJrNCfbpzSWuvr9HrT58+zd69e1m5ciUAOp2OkSNH8s0339C/f38mTZrEvffey8GDBxk4cCDDhw+nV69eFbb3xRdfsGDBAs6fP09+fj5FRUV06tSp1D7t27dHq9WWPA4MDOTo0aM1eh+icmwyoN2d7MkqqHrPQ4jyFNh74nLN47FH15LU+W4WZxwptV+ULpXp7VLxbePCU+d70HZzDEpySo2Off1edzsMTdqR792MXCc/ckwuZOVUr9ddE2GBEXg4+5Q8zslP59ylWJwd3PB28+eXPQvIzE1h3O3/BqBL8HjW/vU4L32xmFaNe5ORl0JuwXlu7z0ZO8fbMClp5Bb+xt39ZlGkZGHcuo+wkE4Ehz/A6bjj2Os24+LbjFzXIKJTNnDvHXfg5eNZfA0+P5eigvySSw7Wxv4f196rauHChRiNRoKCgkqeUxQFe3t70tPTGTx4MOfPn+e3335j48aN3HHHHUyZMoX333+/TFvLly/nmWeeYe7cufTs2RM3Nzf+7//+jz179pSu+R+9fo1Gg9lsvWMcbIlNBrSXs54L6VU9uSdE+XK17vj847lnD/3G5S6D+S39WJn9U+xyeS30IA6PapmU1JVe21Ig5rxFayrudR9BH30EF/7R6/byoyg0gsKAluS7Nf671+1Qa73u85dP8/Gvz5U8/uv0Ov46vY6bWg3koX4vkpWXSlpOcsl2X/dAbms/nG3Hf2b36bXodQ54uvjSufltALg6euHu7MOBk8fYF7URZ70Hjd27knDeny9WzmTkrc+yIfJH/tj9F3dEjMbPeRxXLrPaOYKjo4K9gwl7vRGt3ohOd20PvggoKDlFbzLmFw+yK8zHUJhHUX5erQa8vYNjtV9rNBr59ttvmTt3LgMHDiy17d5772Xp0qVMnTqVRo0aMX78eMaPH0/v3r154YUXyg3oHTt20KtXLyZPnlzyXHR0dLXrE5ZnkwHt6SyjC4XlZGv+OdwLNCi8FbmB1I59+SvjdLmvK9SYmBdwmI8egDGZEQzZbUAXebK2y0WbnoxT+kac2Fi2192sHYbgv3vdjn41utZ9RavGnfh04iYApn55B08MfIOOoVcHeD3U78VS+ydnXmDPmbX8+94v8fcM5rf9SzgSu7Nku0aj4bH+r7Ji9+fkFmTSLrgHPVsPZn3k97QO6kKzRq1xcXBDUcw4O5R37VmDoVCHobDqf96uBLze0YROb0SnN6DTGtBUcA2+qgHv4Oxc5ZquWLNmDenp6Tz22GN4eHiU2nbfffexcOFCkpOT6dq1K+3bt6ewsJA1a9bQtm3bctsLCwvj22+/Zd26dYSGhvLdd9+xb98+QkNDq12jsCwbDeiaXecR4lqZuJX7vL3ZwLwTfzG+dSdOZVfcQ1Y08F/PE/x3MPTv05Ixh1xw2XkUTHU7mYnGZEQfcwR9TPm9bkNoBAX+Lcl3b0yu1pOsQj1ZGSaL9rrNZhOLN81iSLfx+HtWfE9wi8BwZoyYX/I4KSOevWc28u/7vuTD1dPpF34v7YK7887yxwkLDCfIp4XFagQNRQU6igp0QNV6vDcKeBefltWuauHChfTv379MOENxD3rWrFncc889vPTSS8TGxuLk5ETv3r358ccfy23vySefJDIykpEjR6LRaBg9ejSTJ0/mjz/q3wQwtkqjKFZ6saYGXvvlGN/utuwpRdFwfRq2j7svfFjh9svuATwUHMzFvKRKtxlR5M/Ek43x23IUJb/AEmXWCkWrw9isHYXBbSnwDiHPqRHZZheycuzIzynb6y6vB32tvMIcZiwehp3m6kQmiqKgoGCnsWPKXe/ROqhz6RoUhY9+fY7bI+6jZeOOvLDoX3zw6G/o7R1ZuOENWgRG0LfDPZZ947Vk8JPhNO/USO0yRD0hPWghbiDFVPYU97UaZSXyebIL47w9yCjKrFSbR/RJTOmYRFAHd6adi6DFxjMo6RkWqNayNCYj9jFHsI85Uua+brOHL0XNO1EYEEaeWxC5Ok8A7LQV30bhqHfm5fsXlHpux/HVnLl0iMcGvI6PW9nbs3af+h0XR3ciQnqRV5gNgMlsLPmvUo8GLDm6WPflt61bt9KvXz/S09Px9PRUu5w6pdFo+Pnnnxk+fLjapZSwycUyPJ2s+5dA1C/JBqcb7hN6OZpP8rQ4aqs2SveiNot/hx3k0QkGDo3rjqZJ4+qWWefsMlNwPLQR3W/zyfj2BQzfFN8X63FwPo2OzaFp9q9EeMWx/fjnLN89BydXHXYaOxp7h5b6cnXyRKfV09g7FAf70t/r7Px01h5cyv23TAHA2cGNAM+mbDm6kpjE45y+eIjQgPZ1/t6ry8GlZn2i8ePHo9FomDNnTqnnV61ahUZTtftL+/bty/Tp00s916tXLxISEso9jV4bBg4ciFar5a+//qqT411PQkICgwcPVruMUmyyB+1l5Z9SRf2SaKjcwJ5O8ZG81/JWntFcxFTFxTKy7QqZHXQI7UMaHk3tTP8d2WhOnq1OuXXueEE+4+PjSx6/l5QISYkMP7qHWYGNKUq4RL7BQM/CiaV73e5B5Go9cXKyq3AKzJ92fsYdHR/A0+XqaeGx/V7kuy3vsvXYSvp3fIAQvza1/A4tx8W9ZrdZATg6OvLuu+8yceJEvLy8LFDVVXq9vs7m646Li2P37t1MnTqVhQsXcvPNN9fJcf+pqKioTt93VdhmD1pOcQsLulBY+YFC/aL+5BWnsGofy4TC1z5HGTk8lqXT2lJ4czhUsWdU13o4u3CidZsyX7MCi88GzApszJKmzYCrvW6PP74gcNmrhH0/jbcv/8U6fyd6n/+CHsp2IrzOExaYj3+AHZOHz6RPh+Gljhfi14ZXRy7ivfGrGNx1XF2/3Wqz02lwdK1556F///4EBAQwe/bsCvdJTU1l9OjRNGnSBGdnZ8LDw/nhhx9Kto8fP55t27bx0UcfodFo0Gg0xMbGsnXrVjQaDRkZGWRmZuLk5FRmtayVK1fi4uJCTk4OABcvXmTkyJF4eXnh4+PDsGHDiI2NveH7WLRoEXfffTeTJk1i2bJl5OaWntynb9++TJs2jenTp+Pl5YW/vz9fffUVubm5PPLII7i5udGiRYsyg9pOnDjBkCFDcHV1xd/fn4ceeoiUlJRS7U6dOpVnn30WX19fBgwYABSf4l61alXJfhcuXGDUqFF4e3vj4uJCt27dSu4Rj46OZtiwYfj7++Pq6kr37t3ZuHFjqTpCQkKYNWsWjz76KG5ubjRt2pSvvvrqht+Xa9lkQHtJQAsLis+v2kje+49vYKJHeI2P+4trFA/1O8mH05uR0b8r2PDiBBqTEftzR3Hdtgzfn9+j6Q/P0/7HSfRcM5G+h16nV+ZKujodpa1/Gk0bm/H00aHVWfcHl3+yRO8ZilelmjVrFp988gkXLlwod5+CggK6du3KmjVrOHbsGBMmTOChhx4qCZiPPvqInj178sQTT5CQkEBCQgLB/1hpy8PDg7vuuoulS5eWev77779n2LBhuLq6kpeXR79+/XB1dWX79u38+eefuLq6cuedd1JUVFThe1AUhUWLFjF27FjatGlDq1atWL58eZn9lixZgq+vL3v37mXatGlMmjSJ+++/n169enHw4EEGDRrEQw89RF5eHlB8mrpPnz506tSJ/fv3s3btWpKSkkpNXXqlXZ1Ox86dO/nyyy/LHDcnJ4c+ffpw6dIlVq9ezeHDh5kxY0bJBC05OTkMGTKEjRs3cujQIQYNGsTQoUOJiyu9ytrcuXPp1q0bhw4dYvLkyUyaNIlTp05V+H35J5scxR2flkfv97aoXYawIeecx6ExV+1e4de73MXKdMtNidjS4MOkqGYEbz6Bkp1jsXbrK8VOi7FZWwqD21HgE0Keox/ZigvZOXbklTPCXG2BLTwY8ULXGrVxZXWpVatW0bNnT9q1a8fChQtZtWoV99xzD9f7c37XXXfRtm3bkklL+vbtS6dOnZg3b17JPv8cJPbzzz8zbtw4kpKScHZ2JisrC39/f1asWMGQIUP45ptveO+99zh58mTJNfCioiI8PT1ZtWpVmQlVrtiwYQNjxozh0qVL6HQ65s2bx08//cSff/5Zsk/fvn0xmUzs2LEDAJPJhIeHByNGjODbb78FIDExkcDAQHbv3s3NN9/Ma6+9xp49e1i3bl1JOxcuXCA4OJjTp0/TqlUr+vbtS2ZmJocOHSpV07WDxL766iuef/55YmNj8fb2rtS/Tfv27Zk0aRJTp04FinvQvXv35rvvvgOKP5QEBATwxhtv8OSTT1aqTZu8Bh3g4YjWToOpPk3SK6ya4uCJJr9q03a+GrmOlI53sD3DMpOTRNmn8my7VHzaODMtrjvtN8eiJF22SNv1kcZswv7cMezPHatghHlHCgOurBzmVTyHeaYJk1GdvwuuXpbpQV/x7rvvcvvtt/Pcc8+V2WYymZgzZw7Lli3j4sWLFBYWUlhYiIuLSzktVeyuu+5Cp9OxevVqRo0axYoVK3BzcysJ3gMHDnD27Fnc3ErPFVBQUHDdWckWLlzIyJEj0f29utfo0aN54YUXOH36NK1bty7ZLyIiouT/tVotPj4+hIdfPTvl7+8PQHJyckk9W7ZswdW17J0X0dHRtGrVCqBkMZGKREZG0rlz5wrDOTc3lzfeeIM1a9Zw6dIljEYj+fn5ZXrQ19av0WgICAgoqbUybDKg7bV2NPZ0JD5NpvsUlmF08ERfxYDWmY28f3wHj7XtwdGsGIvVkmqXx8yQQzg8omVicldu3ZYC0XLf/7WKr3VvwpFNXDseubxed47iSmaOptz7ui3J1bv603yW57bbbmPQoEG8/PLLjB8/vtS2uXPn8uGHHzJv3jzCw8NxcXFh+vTp1z3tXB69Xs99993H999/z6hRo/j+++9LBavZbKZr165lToMDNGpU/v3eaWlprFq1CoPBwOeff17yvMlk4ptvvuHdd98tea68ecCvfe5Kr/3KqWez2czQoUNLtXFFYGBgyf/f6IOKk9P179x44YUXWLduHe+//z5hYWE4OTlx3333lfn+1nQec5sMaIBm3i4S0MJiCvWeVGdkg1NRHp+ePca40DDO516ybE0aEx/7H+bjB2B0ZjhDdxvRHar9qUTrs+v2ut19KGrekYKAlhR4WL7X7WbhgAaYM2cOnTp1KukZXrFjxw6GDRtWsiyl2WwmKiqq1LSfer0eUyVmsxszZgwDBw7k+PHjbNmyhbfeeqtkW5cuXVi2bBl+fn64u1duyc+lS5fSpEmTUgOyADZt2sTs2bN55513Sj4AVFWXLl1YsWIFISEh1W4Dinu+CxYsIC0trdxe9I4dOxg/fjz33FM8QU5OTk6lBsZVlU0OEgNo6lP9OW+F+KcCXfXXG/bOTeHzhAR8HCx7S8y1fvA4yYN3RvHF02Hk9OkM1ywPWNu+Sk2l3elTzE6u3ExqB/PyCD99intiz5V6flduLoNjoukRdYaXEi5RdM311GyTicEx0VwyGCxa+7XsslJxjNyM59ovCVj2GmHfT6PzionctnkavWM/p4d5Gx3/HmEeEKDF2a1qAeDpZ/m/SeHh4YwZM4ZPPvmk1PNhYWFs2LCBXbt2cfLkSSZOnEhiYmKpfUJCQtizZw+xsbGkpKRU2LPr06cP/v7+jBkzhpCQkFK3Q40ZMwZfX1+GDRvGjh07OHfuHNu2bePpp5+ucADbwoULue++++jQoUOpr0cffZSMjAx+++23an8/pkyZQlpaGqNHj2bv3r3ExMSwfv16Hn300Up9GLli9OjRBAQEMHz4cHbu3ElMTAwrVqxg9+7dQPH3d+XKlURGRnL48GEefPDBWlnhy2YDupm3BLSwnBy76gc0QHDqeT7LMuGsq92fy83OsTza6yhvPhNA8l3d0dzgVF1NHc3P53+ZGbSu5DKK2SYTLyUmcLNz6VOMZkVhRsIlRnp6sbRpM44WFPBTRkbJ9rmXLzPS04vGKoxk15hN2Mcew3X7cnz+HmHe7scnufnXifQ9+Bq9MlbQ1fEw7fxSadrYjJevPVr7sn9aPfxq59/irbfeKjM47NVXX6VLly4MGjSIvn37loTNtZ5//nm0Wi3t2rWjUaNGZa6fXnFlnu7Dhw8zZsyYUtucnZ3Zvn07TZs2ZcSIEbRt25ZHH32U/Pz8cnvUBw4c4PDhw9x7771ltl25tr1w4cIqfgeuaty4MTt37sRkMjFo0CA6dOjA008/jYeHB3Z2lY87vV7P+vXr8fPzY8iQIYSHhzNnzpySdbE//PBDvLy86NWrF0OHDmXQoEF06dKl2nVXxCZHcQOsP57IhO8OqF2GsBGrW/5ORPx/a9zOzuY3M1WTjLGKI8KrK9DkxlPnWhK2KQolLd2ibeeazdwXe45X/QP4MjWFNo6OvOTnf93XPHfpIs30euyATTk5/BxSvHJSqtFI7+izHGrZCgc7O+ZeTibPbOZV/wAO5uUxOzmZH5s1Q2vl94RfodhpMTZtQ1FwO/J9Qsh3DWTAy3eisasf9QvrYLM96DC/68+fLERVZFSwolVV3RLzF2/o6245vwRtNi+FHeSRCYXsH9cNTXCQxdp+OymRPq6u9KrkyOCVmRnEGwxM9vEts81bq6WRVsfOvFwKzGYO5OXTysGBIkXhzaQkXg/wrzfhDFd63cdx2fE/fFf9H2H7vpRwFlVmswHdzMcFvc5m356oY2lK1W5PuZ5/ndzE0+51O390jqaI94IiGTU2mXUTO2FuX/1lDwF+z8riREEhz/hWbmWm2KIiPrx8mfcCG6MrJ2g1Gg0fNG7MF6mpDI09R1tHB0Z4eLIgNZWbXZxx0Ngx5vx5hsTEsDTdsmcC6oJDWPVnlxMNl82O4tbaaQj1ceF0UrbapQgbcNlo2WvHjx/+g6Qud/Nj+hGLtnsjJhQWeh9j4b9g6O1tuH+/Hse/jkIVrnQlGAzMTk7i6ybBOFTiup7p7+vLU3x9CdFXPBa+q7Mzy5uFlDyOLSpidVYmK0JCGRd3nnFe3tzq4sKw2HN0c3KitaPlR0XXFocwS65XLRoKmw1ogDB/VwloYRFJRsv1oK946dDvpHQexMb04xZvuzJ+dT3Lr32hR8+mPHbMF++tR1EqcZ/s8YICUk0m7j8fW/KcCdifn8/36elEtmpd6nR0rtnMsYICThYU8E5S8UhvM6AA4adP8XWTYG7+x2lyRVF4PTGBGX5+KIrCycJCBrq54WRnRzcnZ/bl59WrgNa3kIAWVWfTAd3a343fSFC7DGEDEgotPwLXTjEz58gWJnToxcFM9Vau2utwkb1dL9K8oxdTzobSdONJlOyKP9j2dHHml5DS19FfSUwgVK/ncW+fMteKXe3syuz/Q0Y6e/LymNc4iKByRmavyMzEU6vldlc3Mv++Pcb4dy/fiEJ9myTQIaxmlxREw2TTAd25qafaJQgbcbEKK1pVhYOxgI9PH+ThsHZE55R/32hdidGl81ybdLxaOTEtvjvhm8+jJJadltDFTktLh9L3WTtpNHhqtbT8+3arDy4nk2w0MiewMXYaTcnzV3hrtejLeR6KR3R/kZrC0r9XwPLQammu1/Ntejq3uLjwV24eE7x9LPW2a52duzv60BC1yxD1kE2Pourc1AsZOCksIS7fsvMoX8sjP4Mv4uPwcyw7ulkN6Xb5vNnsEGPGZ7L9sS7QMqTKbaQYjSRUc1KR2clJPOLtg/81PetZAYH8kZ3FpAvxPOrtTUQt399tSU4dO5ZMSSlEVdjsfdBX3DlvO6cS5Tq0qLlzLo+gMRXWWvtn/Fsz3kNLtsH6VqoamdmGf+0xY3/ghNql1Du+T02j0eTJapch6iGb7kEDdG1We9MriobF7Fi7P0utkk7zUZELejvrW898mccpxgw8w/zpLcju2xlqMM9xQ+PcqZPaJYh6SgJaiEoyOHjceKca6h67j3d0QWiwzlOiW53O81jPo7zxtB9Jd3dH4yxT6l6XVotjREe1qxD1lM0HdJemEtDCMorsPevkOHee3sYM17Y33lFFx/XJTAs/xLSpeqIe6IHGp3KL2jc0Di1bonW1/C16omGw+YAO8XXB19X6ThmK+idPW7MFM6pi7NG1jPeMuPGOKkvU5vBKi4M8/Hg++8Z3Q9OsidolWRWnTtJ7FtVn8wENxaO5haip3DoMaIBnD/3GEK8OdXrM6sqzM/B/gZE8MDqRPyZ2xBze6sYvagCcO3dWuwRRjzWIgJbr0MISMi20YEZlaVB4+/BGbvKsP2GnaGCR93FG3R3D4qdak98rAqqwzJ+tcZKAFjXQIH5zJKCFJWRQ99cS7U1FfHRiD23cmtX5sWvqd5doHu5zgvemNyFtUDc0lVwz2lZofX3RN22qdhmiHmsQAR3RxANnvfbGOwpxHWkmdZYwdSnMZn5sFEHO119r2Vrtd7jEk10ief4pN86P6IHGo24vFajFpVdPtUsQ9VyDCGgHnZbeLa1jliZRfyWb1LulqFFWIp8np+Gpr/1bvWrLeV0GL7Q+yONPmjk6tgeaxgFql1SrXHvfpnYJop5rEAENMKCdbf8xELUvyaDuPb+hl6P5JE+Lo7Z+nyrOtCvgreCDjB6XxtbHu6C0bq52SZZnZ4dr71vVrkLUcw0moG9v44dWJuYWNXCpSP35nzvFR/Kexh+tpv5fsjFqzMxvdISRI+L435T2FHVvr3ZJFuMUEYHW01OVYy9evBhPlY5dU3379mX69Olql2E1GkxAe7vo6Sq3W4kaiC+wjvWH+0X9yStOYWqXYVH/cz/N2P6n+eSZ5mT161LvpxJ17VPz09vx8fE89thjNG7cGL1eT7NmzXj66adJTU0t2SckJIR58+bV+FhVtXXrVgIDA1EUpcJQXbVqlSwSUkMNJqAB+rfzU7sEUY/F51tHQAPcf3wDEz3C1S7D4nY4xvH4zUd4bbovCUO7o3Gpn7Nwud5+e41eHxMTQ7du3Thz5gw//PADZ8+e5YsvvmDTpk307NmTtLQ0C1VaeYZrVidbvXo1//rXvySAa1mDCmi5Di1qItdkh2JvPYExNfI3RnjZXkgDnLJP4ekOh5gyVcfpkT2w860/6z/bBwfj2Lp1jdqYMmUKer2e9evX06dPH5o2bcrgwYPZuHEjFy9e5JVXXqFv376cP3+eZ555Bo1GUyYs161bR9u2bXF1deXOO+8kISGh1PZFixbRtm1bHB0dadOmDfPnzy/ZFhsbi0ajYfny5fTt2xdHR0f++9//lmy/EtBVMXPmTDp16sR3331HSEgIHh4ejBo1iuzsilcbXLt2LR4eHnz77bcAjB8/nuHDh/P+++8TGBiIj48PU6ZMKfXhIT09nXHjxuHl5YWzszODBw8mKioKAEVRaNSoEStWrCjZv1OnTvj5Xe287d69G3t7e3JyileV02g0LFiwgHvuuQdnZ2datmzJ6tWrq/Teq6tBBXSorwstGlnPH1hR/5gcPdUuoZRXI9dxm6d1z9tdE8l2ubza/CBjH89lz/huaEKC1S7phtxq2HtOS0tj3bp1TJ48Gad/rHsdEBDAmDFjWLZsGStWrKBJkya8+eabJCQklArgvLw83n//fb777ju2b99OXFwczz//fMn2r7/+mldeeYV33nmHkydPMmvWLF599VWWLFlS6ngvvvgiTz31FCdPnmTQoEEAHD9+nMTERO64444qv7fo6GhWrVrFmjVrWLNmDdu2bWPOnDnl7vvjjz/ywAMP8O233zJu3LiS57ds2UJ0dDRbtmxhyZIlLF68mMWLF5dsHz9+PPv372f16tXs3r0bRVEYMmQIBoMBjUbDbbfdxtatW4HiMD9x4gQGg4ETJ4qXUt26dStdu3bF1fXqbZVvvPEGDzzwAEeOHGHIkCGMGTOmTs5iNKiABujfrn7eSyqsg0HvqXYJpejMRt4/voNwdxscCX2NAo2RuYGRPDAqgd+ejMAUUbMeam1yvaNmAR0VFYWiKLRtW/4Hr7Zt25Keno7JZEKr1eLm5kZAQAABAVfPEBoMBr744gu6detGly5dmDp1Kps2bSrZ/tZbbzF37lxGjBhBaGgoI0aM4JlnnuHLL78sdazp06eX7NO4cWMAfvnlFwYNGoSjY9Uv+ZjNZhYvXkyHDh3o3bs3Dz30UKm6rpg/fz5PPvkkv/zyC8OGDSu1zcvLi08//ZQ2bdpw9913c9ddd5W0ERUVxerVq1mwYAG9e/emY8eOLF26lIsXL7Jq1SqgeCDalYDevn07HTt25Pbbby95buvWrfTt27fUMcePH8/o0aMJCwtj1qxZ5Obmsnfv3iq//6qq3yMxqmFgO3++3Bajdhminiq090D9sdylORXl8enZY4wLDeN87qUqv96QbiBxeSI5R3IwG8w4+DsQ9FgQTiEVv1OzwczlXy6TsTsDY6YRnZcOv6F+eN1WPBAz51gOl767hDHLiHsXdxo/0hg7XXF/wJRnIvqNaEJmhKD3qdpCNooGlnidYMldcGff1ow66IjzrqNgNlf5fdcGrY8Pzl271uoxFEUBuO71X2dnZ1q0aFHyODAwkOTkZAAuX75cMgDtiSeeKNnHaDTi4VH6Pvtu3bqVafuXX35h8uTJ1ao9JCQEN7erU+ZeW9cVK1asICkpiT///JMePXqUaaN9+/ZotVfvYggMDOTo0aMAnDx5Ep1Ox0033VSy3cfHh9atW3Py5EmgOKCffvppUlJS2LZtG3379qVp06Zs27aNCRMmsGvXrjKD3iIiri5c4+LigpubW5m6a0ODC+jOwV74ujqQklOodimiHsrTuuOpdhHl8M5N4fMEFx5q5EVqYXqlX2fKNRHzdgwubV1o9lwzdG46ii4XYed8/ZNr8fPjMWYaCXo0CL2fHmO2EUzF2xSzQvyX8TS6qxGu4a7EfxpP+tZ0fPoXX0dOXJ6Idz/vKofzP611iWZtb+h8UxATjvvju+UoSqG6v9ced9+NRluzW+DCwsLQaDScOHGC4cOHl9l+6tQpvLy88PWtePIle3v7Uo81Gk1JsJv//jDz9ddflwoyoFTwQXEYXSsxMZGDBw9y1113lTzn7u5OZmZmmRoyMjJwdy89a1x5dZn/8eGqU6dOHDx4kEWLFtG9e/cyH0Su18aV9/hPiqKUtNOhQwd8fHzYtm0b27Zt48033yQ4OJh33nmHffv2kZ+fz623lr6HvTJ114YGd4rbzk7Dvzo2VrsMUU9l29XtghlVEZx6ns+yTDjrKj+hyuXfLmPvY0+Tx5vg3NwZfSM9ru1ccfCreDKU7CPZ5J7KpdmzzXBt74q+kR7n5s44tyw+rinHhCnbhPft3jgGOeLW2Y3CS8XBmRuVS35sPj4DLTfo65A+gUmdI3nuaTdi7+2BxlO92dY8RoyocRs+Pj4MGDCA+fPnk5+fX2pbYmIiS5cuZeTIkWg0GvR6PSaTqUrt+/v7ExQURExMDGFhYaW+QkNDr/va1atX07Nnz1IfDtq0acP+/fvL7Ltv3z5aV2OwXIsWLdiyZQu//PIL06ZNq9Jr27Vrh9FoZM+ePSXPpaamcubMmZJLBleuQ//yyy8cO3aM3r17Ex4eXnJZoEuXLqV6+WpqcAENMKqH9Q80EdYpq45XtKqq9peO8YHJE51d5U6OZUdm4xTiRNyncZycdpKzr50lbev1B79kR2bjFOpEyu8pnJp+ijMvniHhxwTMRcU9Cq2bFp2njpzjOZiLzOSeycUx2BGz0cylJZcIejgITS1MGhSnzWBGq4M8/qSJyLHd63wqUcd27XBsbZmVxz799FMKCwsZNGgQ27dvJz4+nrVr1zJgwACCgoJ45513gOJTxtu3b+fixYukpKRUuv2ZM2cye/ZsPvroI86cOcPRo0dZtGgRH3zwwXVft3r16jLXhCdPnkx0dDRTpkzh8OHDnDlzhs8++4yFCxfywgsvVP3NA61atWLLli2sWLGiShOXtGzZkmHDhvHEE0/w559/cvjwYcaOHUtQUFCpuvv27cv3339PREQE7u7uJaG9dOnSMtef1dQgA7qVvxudm3qqXYaoh9IVdRbMqIpbYv7iDf31e0JXFCUXkbY5DX2AnpDnQ/Du503C0gTSd1Z8mrwouYi8M3kUXiyk6VNNCXwwkKx9WVz6rvj6t0ajIXhyMJdXXybq5Sicmjrh1duLlN9ScG3nikavIebtGM78+wypG1MrPE51ZWoKmBV8iNHj0tj8RGeUNi1u/CIL8LjnHou11bJlS/bv30+LFi0YOXIkLVq0YMKECfTr14/du3fj7e0NwJtvvklsbCwtWrSgUaNGlW7/8ccfZ8GCBSxevJjw8HD69OnD4sWLr9uDzs3NZdOmTWVurwoJCWHHjh1ER0czcOBAunfvXjKy+v7776/eNwBo3bo1mzdv5ocffuC5556r9OsWLVpE165dufvuu+nZsyeKovD777+XOk3dr18/TCZTqTDu06cPJpOJPn36VLtmS9MoFZ20t3HL9sXx4oqjapch6pnZzY8y+tJstcuolAUdB/NR1vHr7nP8seM4hjrS4j9XQ+zSfy+Rfy6fFq+WH2zn/u8ceWfyaPNRG7TOxdcsM/dnEv9ZPO2+bIedvuzn/sLEQs5/eJ4Wb7Tg3Oxz+Az0wS3cjahXogidEYpjcO1OAjMiuxUj9tqh33usVtrX2NsTtn0bOi/bna1w5cqV/Oc//ym5HUnUvgbZgwYY2rExrg4NboycqKFkY/25j/7xw38wyiviuvvoPHU4Ni4djg6NHTCkGip4Bdh72mPvZV8SzldegwKGtLKvUxSFi4suEjAqABQoOF+ARzcPdO46XFq7kHsqt4rvrOpWup1h7B2n+OiZUDLvsPxUoq79+tl0OAO4urry7rvvql1Gg9JgA9pZr+PuiEC1yxD1TKLBeqb7rIyXDv1Of6+KF6FwbulMYWLpkc9FiUXY+9pX8Iri1xgyDJgKTKVegwbsvcu+Ln17OjpXHe6d3eHvga+KSSn5r2Kuu5N4Ox3jeaLHEV6d7sulf/VA42qZD1weIyx3ettaDRw4kKFDh6pdRoPSYAMaYGR3GSwmqsYaVrSqCjvFzJwjW+jiUf7iGj4DfciLziP512QKkwrJ2J1B2tY0fG6/Oso68X+JXPjqQsljj5s90LpqubjgIgUXC8g9nUviskS8enuVOb1tzDJyefVlAscWfxjWumhxaOxA6vpU8s7mkXsyt2T0d106bZ/C9PYHmTRFx6lRPdD4VX+9eG0jX1x797ZgdUIUa7DXoK+4c952TiVWPBesENdq7pzPZvNjapdRZZlOnjwc1o7onAtltmVFZpH0UxJFiUXoG+nxGeSDd1/vku0Xvr5AUUoRzV+6OltZ4aVCLi29RF5UHlpXLR7dPfC/179MQMd/Ho9zS+eSe6AB8mLyuPj1RYxZRnwG+uA3TP1FbBwVHZOS2tNz22WIiavSa70fexT/ao5WFuJ6GnxAf/PnOd5cI4MeROXY2ymc0Y9FQ/37tUn0bMKYQD+SCyp/O05Do1FgTGY7huw2oIs8eeMX2NnR4o/f0TdrVvvFiQanQZ/iBhjRJQi9rsF/G0QlGcwacHC/8Y5WKCDjAp+n5eJmb/23iqlF0cB/PU/w4OAoFjzVitzeneA6M4O59u0r4SxqTYNPJk9nPcNkZjFRBUYHT7VLqLZWSaf5qMgFvV3NptlsCNa7xPDIrcd4e3oAl4d0R+NUdoCg9/iHVahMNBQNPqABJvZpjqw7LirL2la0qqrusft4RxeEBvmhr4wj+iSmdDzEM1NdOHdfDzRenkDxzGEu5SzmIISlSEADYX5u3NFGlqEUlVOgq5+nuK915+ltzHC13XWka8MFXSYvtjzIoxMMHBrXHZdJ9W+woKhfJKD/Nqmvba+nKywn1wYCGmDs0bWM97z+RCairGy7Qha3SsT7joFqlyJsnAT037o286Z7iG3PBCQsI0dj3QtmVMWzh35jiFcHtcuodx5u/3ClFyQRorokoK8xuV/5kzkIca1MK1/Rqio0KLx9eCM3eVpmFaaGwMvBixEta76spBA3IgF9jX6t/ejYRL21ZEX9kFYPVrSqCntTER+d2EMbN7ldqDLGtR+Hk65+zSgn6icJ6H946o6WapcgrFyKqe6npqxtLoXZzI+NIshZBktej4+jDw+2eVDtMkQDIQH9D3e09Sc8SHrRomL1aUWrqmiUlcjnyWl46uXnvyKPhz+Os73tfUAT1kkCuhzTbpdr0aJiiUX1a0Wrqgi9HM0neVoctQ5ql2J1AlwCeKD1A2qXIRoQCehyDGwfQJemnmqXIazUxXq2olVVdYqP5D2NP1pNxVNcNkRPRjyJXiszsIm6IwFdgdeHtpfZxUS54vJttwd9Rb+oP3nFSc4kXdHMvRnDwoapXYZoYCSgK9Ax2JN7OgepXYawQpcK9SgNoHd5//ENTPQIV7sMqzC542S571nUOQno6/j3nW1w0dv+H2JRNYqiQXH0VLuMOjE18jdGeDXskI7wjWBw6GC1yxANkAT0dfi5O8rkJaJcRoeGM9L51ch13ObZMOft1qDhpZteQiPXu4QKJKBv4LFbQ2niZduDgkTVFdl7ql1CndGZjbx/fAfh7g1vvvp7Wt5DB1+ZClWoQwL6Bhzttbw8pGH2HkTF8u0bTg8awKkoj0/PHqOZS8NZO91N78bTXZ5WuwzRgElAV8KQ8EBuCvVWuwxhRXLtbjwf9/bzRob+kEfjudlo3shi1SlDqe2KojBzawGN52bj9E4WfRfncjzZVOkafjxmQPNGFsN/zCv1/NIjBoI/zMb73SxeWF9QaltshplWn+SQVahU+jhXeOem8HlCAj4ODWNRmSmdpuDtKL/3Qj0S0JX02tB22MllKPG37EqsaJVbpNDR345Ph5R/W9Z7O4v4YHcRnw5xZN8TLgS4ahjwXR7ZlQjP8xlmnl9fQO+mpQcxpuSZefzXfN4f4Mi6sS4sOWzgtzNXPxhM+i2fOf0dcHeo3g9zcOp5Pssy4ayz7dm0wjzDGNl6pNpliAZOArqS2jf2YFSPpmqXIaxEJjdeMGNwS3vevt2REW3ty2xTFIV5e4p4pbcDI9ra08FPy5LhTuQZFL4/aiintatMZoUxK/N5o68Dzb1K/wrHpCt4OGgY2cGe7kFa+oVqOXHZDMD3Rw3otZpy66mK9peO8YHJ02ZvO9Kg4eWbXrbZ9yfqDwnoKnhpcBuCPGXAmKj5ilbnMhQScxQGtrgaAg46DX1CdOy6cP3T3G9uK6SRi4bHupSd1aqltx15BoVDCSbS8hX2XTQR4a8lLV/htS0FfDrYMpOs3BLzF2/oQy3SlrW5v9X9dA/ornYZQkhAV4Wboz3v3RchM4wJLptqtmBGYk5xr9bftfQPk7+LpmRbeXbGGVl4yMDXQ8sPWi8nDUuGOzFuVT49vs5hXEd7BoXpeH59AdN66DmXYabzlzl0mJ/DTyeu31O/kX+d3MTT7u1r1Ia1CXQJ5Nluz6pdhhAAyDmcKrolzJeHbm7Gt7vPq12KUFGSwTJnUv75WU9Ryj53RXahwtif8/l6qCO+zhV/tr6nrT33XHMae2uskaPJJj4d4kjYxzn8cK8TAa4aeizI5bZmWvxcqv85/fHDf5DU5W5+TD9S7TasycyeM3Gxt83VykT9IwFdDf8e3IbtZy4Tm5p3452FTUooqtkgqQDX4lBMzFEIvGa8WXKegr9r+YEZnW4mNkNh6A/5QD4A5r/Hk+nezOL0VFdaeJd+baFRYfJvBfx3hBNn08wYzdAnpPjXvpWPHXsumBjaumYn0l469DspnQexMf14jdpR24iWI+gV1EvtMoQoIae4q8FZr+P9+zvKqO4G7GJhza7lhnpqCHDVsCHGWPJckUlhW6yRXk3Kn162ja8dRye5EPnk1a9/tdbRL1RL5JMuBHuU/YF8a3shg8N0dAnUYjKD0Xx1hLjBBKaq321Vhp1iZs6RLXTxqL+z7vk7+/NCtxfULkOIUqQHXU3dQrx5vHdzvtoeo3YpQgXx+Y43/HibU6RwNu3q9eRz6WYiE014O2lo6mHH9Jv0zNpRSEtvO1r62DFrRyHO9hoeDL96enrcz/kEuWmY3d8RR52GDn6lw9vTsTiU//k8wPFkE8uOG4mcWHzKto2vHXYaDQsPFhHgquFUipnujS0z17yDsYCPTx/k4bB2ROdcsEibdem1nq/hqq/ZwD8hLE0CugaeG9iKLaeSiUrOUbsUUccuF9mjuOjRmIoq3Gf/JRP9lly9DPLs+kKgkIc72rN4uBMzbtGTb1SY/HsB6fkKNzXRsv4hZ9yuuUc5LtOMnabqJ7oURWHCmgI+HOSAi764PSd7DYuHOzLl9wIKjfDpEEeC3C13Es0jP4Mv4uMYE+hHckGKxdqtbSNbj+S2JrepXYYQZWgURbHASa6G6+iFTO6Zv7PUqUPRMET7TEebm6x2GVbnjH9rxntoyTZY/wfXMM8wfrz7Rxy0DmqXIkQZcg26hsKbeMiKVw2UUd8wprysqlZJp/moyAW9Xdn7tK2Jg9aB9257T8JZWC0JaAt4+o6W3Brmq3YZoo4V2rurXYLV6h67j3d0QWgqvGlMfS/2eJGWXi3VLkOICklAW4DWTsMnozvLspQNTL6uYa1oVVV3nt7GDFfrXAluSOgQ7m91v9plCHFdEtAW4uWi54uxXXG0l29pQ1GZFa0aurFH1zLeM0LtMkoJcQ/h9Z6v1+oxFi9ejKenZ60eo6piY2PRaDRERkaqXYqoJEkTC+oQ5MHsEeFqlyHqSFYlVrQS8Oyh3xji1UHtMgBwsXdhXr95ONtXf6KZ8ePHM3z48DLPb926FY1GQ0ZGBiNHjuTMmTM1qNTygoODSUhIoEMH6/i3EDcmAW1h93RuwvheIWqXIepAOhLQlaFB4e3DG7nJs5Wqddhp7Hi397u08GxR68dycnLCz8+v1o9TFVqtloCAAHQ6ubu2vpCArgX/uastPUJloXdbl2a27TWRLcneVMRHJ/bQxq2ZajVM6zyNPsF96uRY/zzFffjwYfr164ebmxvu7u507dqV/fv3l9p31apVtGrVCkdHRwYMGEB8fHzJ66Ojoxk2bBj+/v64urrSvXt3Nm7cWOqYISEhzJo1i0cffRQ3NzeaNm3KV199VbK9vFPcx48f56677sLd3R03Nzd69+5NdHR07XxTRJVJQNcCndaOzx7sQoC7ZZb2E9bpslEWVagKl8Js5sdGEeTsX+fHHhw6mMfDH6/z414xZswYmjRpwr59+zhw4AD//ve/sbe/OmNcXl4e77zzDkuWLGHnzp1kZWUxatSoku05OTkMGTKEjRs3cujQIQYNGsTQoUOJi4srdZy5c+fSrVs3Dh06xOTJk5k0aRKnTp0qt6aLFy9y22234ejoyObNmzlw4ACPPvooRqOx3P1F3ZNzHbWkkZsDn4/twsiv/qLIWPHygaL+stSKVg1Jo6xEPk92YZy3BxlFmXVyzPY+7Xmz15sWbXPNmjW4upaeGtRkqngd77i4OF544QXatGkDQMuWpW/vMhgMfPrpp9x0000ALFmyhLZt27J371569OhBx44d6dixY8n+b7/9Nj///DOrV69m6tSpJc8PGTKEyZMnA/Diiy/y4YcfsnXr1pLjXuuzzz7Dw8ODH3/8seTDQqtW6l6GEKVJD7oWdW7qxTvDZUCGrUowyCnu6gi9HM0neVoc62CCEF8nXz7q9xGOOsuezerXrx+RkZGlvhYsWFDh/s8++yyPP/44/fv3Z86cOWVOI+t0Orp161byuE2bNnh6enLy5EkAcnNzmTFjBu3atcPT0xNXV1dOnTpVpgcdEXF1xLxGoyEgIIDk5PJnu4uMjKR3796levLCukhA17L7uwXz3AD5VGqL4gvkEkZ1dYqP5D2NP1qNZRbrKI+rvSvz75iPv4vlT6m7uLgQFhZW6isoKKjC/WfOnFlyvXfz5s20a9eOn3/+udQ+Gk3ZSV2uPPfCCy+wYsUK3nnnHXbs2EFkZCTh4eEUFZWeC/6fYavRaDCbyz+D5+QkZ4CsnQR0HZh2R0vG9VRvcIyoHXH5MkVkTfSL+pNXnGpnmly9nZ6P+n1EWx/rmSilVatWPPPMM6xfv54RI0awaNGikm1Go7Fk0BjA6dOnycjIKDk1vWPHDsaPH88999xDeHg4AQEBxMbG1qieiIgIduzYgcFgqFE7ovZIQNeRmUPbMyQ8QO0yhAVlG3UoNbifVsD9xzcw0cOycwfYaeyYc9scegT2sGi71ZWfn8/UqVPZunUr58+fZ+fOnezbt4+2ba9+eLC3t2fatGns2bOHgwcP8sgjj3DzzTfTo0fxewgLC2PlypVERkZy+PBhHnzwwQp7xpU1derUksFo+/fvJyoqiu+++47Tp0/XqF1hORLQdcTOTsOHIzvRs7mP2qUICzI7eKpdQr03NfI3RnhZLqRfuekVBjQbYLH2akqr1ZKamsq4ceNo1aoVDzzwAIMHD+aNN94o2cfZ2ZkXX3yRBx98kJ49e+Lk5MSPP/5Ysv3DDz/Ey8uLXr16MXToUAYNGkSXLl1qVJePjw+bN28mJyeHPn360LVrV77++mu5Jm1FZLnJOpZbaGTMgj1ExmeoXYqwgFNBb+OYekLtMuo9o52OpzvewfaMkzVqZ3KnyUzqOMlCVdWNxYsXM336dDIyMtQuRVgZ6UHXMRcHHUse6UHbQFkJyRYU6uTf0RJ0ZiPvH99BuHvzarfxYJsH6104C3E9EtAq8HC257vHetDcVya6qO/yZEUri3EqyuPTs8do5tK4yq99sM2DvHTTS7VQlRDqkVPcKkrIzGfkl38Rl5andimimja0/JmW8f9TuwybEu/TjIcaeZJamF6p/ce2HcuLPV6s5aqEqHvSg1ZRoIcTPz3Zk9b+suhCfZWF6413ElUSnHqez7JMOOtuPEL+oXYPSTgLmyUBrTI/d0eWTbyZTsGeapciqiFdArpWtL90jA9MnujsKp6NeHz78czoPqMOqxKibklAWwFPZz3fP3ETt4b5ql2KqKJUk4wjqC23xPzFG/rQcrc90uERnuv2XB1XJETdkoC2Es56Hd+M786d7WUyk/okWVa0qlX/OrmJp93bl3ru6S5P82zXZ1WqSIi6IwFtRfQ6Oz4b04X7uzZRuxRRSYmyolWte/zwH4zyikCr0fJGrzdUXTZSiLoko7itkKIovPPbSRb8eU7tUsQN9PNOY1He1BvvKGrErHfl6Jjv6disj9qlCFFnpAdthTQaDf+5ux3PD5RVsKzdhULpQdc6Fz/sHl4t4SwaHAloKzb19pbMvb8jDjr5Z7JWsqJVLfNtDY9vhKCualciRJ2Tv/xW7t6uTfjfkz1p7CFrD1ujQrMdioPcx14rQnrDY+vBS5ZqFQ2TBHQ9ENHEk9XTbqVHqLfapYhymBy81C7B9nQeC2NXgpOn2pUIoRoJ6HrC19WB7x+/ifG9QtQuRfxDkV7m47YYe2cY/jkM+wx0erWrEUJVEtD1iE5rx8x/ted9uS5tVQpkwQzL8G0NT2yGTg+qXYkQVkH+ytdD9/19XTpQrktbhTytLDlZYxEjYcIW8GurdiVCWA0J6Hoqooknv8p1aauQYyeDxKpN5whDP4YRX4FeZmUT4loS0PXYlevSz/Rvhb1Wo3Y5DVYmEtDV4t2i+Baqrg+rXYkQVkkCup7Tae14un9Lfp58C638ZWUlNaQr0vOrsvb3wMRtEBCudiVCWC0JaBvRIciDX6fdyoTbmmMnnek6lWKWD0aVpnOEIe/D/YtB7h8X4rokoG2Ig07Ly0Pa8uOEngR7yxSUdSXZKN/rSgntA5N2QY8n1K5EiHpBAtoG9Qj1Zu3TtzG6R1O1S2kQEoqc1S7Bujl5w7D58PBq8GmhdjVC1BsS0DbKxUHH7BHhLHqkO35uMl90bbpUKLe7VSj8AZi6DzqPUbsSIeodWW6yAcjIK+LdtadZti8Os/xrW1xTpwK2K4+qXYZ18WwGd38AYf3VrkSIeksCugE5HJ/Ba6uPczg+Q+1SbIpWY+as4zg0ilntUtSn0ULPydD3ZdDLqX8hakICuoFRFIVl++J5b91p0nKL1C7HZsR4TsGuIF3tMtQV2An+9TEEdlS7EiFsggR0A5WZZ+CjTVF891csBpP8CNRUlP9/sM+MUbsMdbgFwm0vQNfxYKdVuxohbIYEdAN3LiWXWb+fZMOJJLVLqdeOB7+Hy+VItcuoW07ecOt06DEB7OVWMyEsTQJaALA7OpVZv5/k6MVMtUuplw6EfolPwja1y6gbelfoOQV6TgVHWShEiNoiAS1K2XwqiU82n+VQXIbapdQr28J+pNmF1WqXUbt0jtDtMej9LLj4ql2NEDZPp3YBwrrc3saf29v4s/NsCp9sjuKvmDS1S6oXsjU2PN2nnQ46jYE+L4JHkNrVCNFgSECLct0S5sstYb7sj03jk81n2XbmstolWTWbXNFKY1e8qEW/V2QGMCFUIAEtrqtbiDdLHu3B0QuZfLI5ig0nk5CLImWlmW1oRSu9K3QeCzdNBO/malcjRIMlAS0qJbyJB1+N68bpxGy+3BbNb0cTKDTKxBxXpNhCQHs0LQ7lLg+Bo4fa1QjR4MkgMVEtGXlF/HzoIj/ujed0Urba5ahuUnAsL15+We0yqkEDobdB98egzd1yH7MQVkQCWtTYgfPp/Lg3jjVHEsg3mNQuRxXD/ZOZlzld7TIqz8mreOBX10fAN0ztaoQQ5ZCAFhaTXWDgl8hL/LA3juOXstQup05188jmp8KJapdxfRotNOtVfH253XCwl1W4hLBmEtCiVhy9kMmP++JYdzyRlBzbn/Pb36GIPZrxapdRlkYLob2h3TBoMxRcG6ldkRCikiSgRa0ymxUOxqWz/kQSG04kcS4lV+2Sas0554fRmA1ql1F833Jon79D+W5w8VG7IiFENUhAizoVlZTN+hNJrD+RxJELGTZ1y1aM91PY5aWoc3A7e2jeF9oPh9ZDwNlbnTqEEBYjAS1Uk5RVwIa/e9a7Y1Ipque3bZ0JfB19elTdHdCzGTS7BZr3gVZ3gpNn3R1bCFHrJKCFVSgwmDgYl87ec2nsiUnjUHw6BYb6FdhHm36AW/L+WmpdA43aQLOexaHcrBe4N66lYwkhrIFMVCKsgqO9ll4tfOnVongRhiKjmaMXMzh4PoND8ekcissgIbNA5SqvL1/nbrkJPzVaCIyApr2Kw7hZL6s+ba0oChMnTuSnn34iPT2dQ4cO0alTp3L31Wg0/PzzzwwfPrxOa7R2M2fOZNWqVURGRqpdirAS0oMW9UZSVgGH4tI5kZBN9OUcYi7nci4lx2p62ltaLic0flXVX+gWCL4twbdV8Vej1hDUFRysa37vXbt20bt3bwYMGMDatWtLbfvjjz8YNmwYW7dupXnz5vj6+qLTlf/5PzExES8vLxwcHOqi7Ou63nuqazk5ORQWFuLjI4P6RDEJaFGvKYrCpcwCYi7nEJ2cQ0xKLjGXc4m5nENCVkGdDkL7peUfdIz/rvyNWj14t/g7iK+E8d//tbIgrsjjjz+Oq6srCxYs4MSJEzRt2rRk26effsr//d//cf78+QpfX1RUhF6vr4tSK+1676muKIqCyWSq8AONaLjs1C5AiJrQaDQEeTrRu2Ujxt8SypvDOvDfx29i10t3cPyNQWx+rg8rJvXk63HdeO++CF4a3IaJfZozslswA9r5062ZFy0aueDtosfJXouTvRZHezsc7e1w0Nmhv/KltcNeq8Feq0Fnp8FZryXA3ZGWfq50aepJ39aNKAy6GW56Em7/Dwz9CEZ9D49tgKcPwyuJMOUvGPkd3PEadBxllb3kiuTm5rJ8+XImTZrE3XffzeLFi0u2jR8/nmnTphEXF4dGoyEkJASAvn37MnXqVJ599ll8fX0ZMGAAUPxvtmrVqpLXX7hwgVGjRuHt7Y2LiwvdunVjz549AERHRzNs2DD8/f1xdXWle/fubNy4sVRtISEhzJo1i0cffRQ3NzeaNm3KV199VaP3BLB161Y0Gg3r1q2jc+fOODk5cfvtt5OcnMwff/xB27ZtcXd3Z/To0eTl5ZW8TlEU3nvvPZo3b46TkxMdO3bkp59+Krfdbt264eDgwI4dO5g5c2aZywLffPMN7du3x8HBgcDAQKZOnVqy7YMPPiA8PBwXFxeCg4OZPHkyOTk5JdsXL16Mp6cn69ato23btri6unLnnXeSkJBww++NsBKKEELcwMKFC5Vu3bopiqIov/76qxISEqKYzWZFURQlIyNDefPNN5UmTZooCQkJSnJysqIoitKnTx/F1dVVeeGFF5RTp04pJ0+eVBRFUQDl559/VhRFUbKzs5XmzZsrvXv3Vnbs2KFERUUpy5YtU3bt2qUoiqJERkYqX3zxhXLkyBHlzJkzyiuvvKI4Ojoq58+fL6mtWbNmire3t/LZZ58pUVFRyuzZsxU7O7uS41XnPSmKomzZskUBlJtvvln5888/lYMHDyphYWFKnz59lIEDByoHDx5Utm/frvj4+Chz5swped3LL7+stGnTRlm7dq0SHR2tLFq0SHFwcFC2bt1aqt2IiAhl/fr1ytmzZ5WUlBTl9ddfVzp27FjSzvz58xVHR0dl3rx5yunTp5W9e/cqH374Ycn2Dz/8UNm8ebMSExOjbNq0SWndurUyadKkku2LFi1S7O3tlf79+yv79u1TDhw4oLRt21Z58MEHb/wPLqyCBLQQ4oZ69eqlzJs3T1EURTEYDIqvr6+yYcOGku0ffvih0qxZs1Kv6dOnj9KpU6cybV0b0F9++aXi5uampKamVrqWdu3aKZ988knJ42bNmiljx44teWw2mxU/Pz/l888/r9F7uhKkGzduLHlu9uzZCqBER0eXPDdx4kRl0KBBiqIoSk5OjuLo6FjyAeOKxx57TBk9enSpdletWlVqn38GdOPGjZVXXnnluu/hWsuXL1d8fHxKHi9atEgBlLNnz5Y899lnnyn+/v6VblOoS05xCyGu6/Tp0+zdu5dRo0YBoNPpGDlyJN98880NX9utW7frbo+MjKRz5854e5c/Qj03N5cZM2bQrl07PD09cXV15dSpU8TFxZXaLyIiouT/NRoNAQEBJCcnW+Q9Xdu2v78/zs7ONG/evNRzV4514sQJCgoKGDBgAK6uriVf3377LdHR0aXavd73Jjk5mUuXLnHHHXdUuM+WLVsYMGAAQUFBuLm5MW7cOFJTU8nNvTpbn7OzMy1atCh5HBgYeN3vi7AuMipBCHFdCxcuxGg0EhQUVPKcoijY29uTnp6Ol5dXha91cbn+OtlOTk7X3f7CCy+wbt063n//fcLCwnBycuK+++6jqKj0/O729valHms0Gszmikf3V+U9Xdu2RqO57rGu/Pe3334r1TZQZtT69b43N/q+nD9/niFDhvDkk0/y1ltv4e3tzZ9//sljjz2GwXB1utnyalVkXHC9IT1oIUSFjEYj3377LXPnziUyMrLk6/DhwzRr1oylS5fWqP2IiAgiIyNJS0srd/uOHTsYP34899xzD+Hh4QQEBBAbG1ujY9bme2rXrh0ODg7ExcURFhZW6is4OLjS7bi5uRESEsKmTZvK3b5//36MRiNz587l5ptvplWrVly6dKnadQvrJD1oIUSF1qxZQ3p6Oo899hgeHh6ltt13330sXLiw1Mjiqho9ejSzZs1i+PDhzJ49m8DAQA4dOkTjxo3p2bMnYWFhrFy5kqFDh6LRaHj11Vev2zNW+z25ubnx/PPP88wzz2A2m7n11lvJyspi165duLq68vDDD1e6rZkzZ/Lkk0/i5+fH4MGDyc7OZufOnUybNo0WLVpgNBr55JNPGDp0KDt37uSLL76oVs3CekkPWghRoYULF9K/f/8yQQZw7733EhkZycGDB6vdvl6vZ/369fj5+TFkyBDCw8OZM2cOWq0WgA8//BAvLy969erF0KFDGTRoEF26dKn28aD239Nbb73Fa6+9xuzZs2nbti2DBg3i119/JTQ0tErtPPzww8ybN4/58+fTvn177r77bqKiiud679SpEx988AHvvvsuHTp0YOnSpcyePbvaNQvrJBOVCCGEEFZIetBCCCGEFZKAFkIIIayQBLQQQghhhSSghRBCCCskAS2EEEJYIQloIYQQwgpJQAshhBBWSAJaCCGEsEIS0EIIIYQVkoAWQgghrJAEtBBCCGGFJKCFEEIIKyQBLYQQQlghCWghhBDCCklACyGEEFZIAloIIYSwQhLQQgghhBWSgBZCCCGskAS0EEIIYYUkoIUQQggrJAEthBBCWCEJaCGEEMIKSUALIYQQVkgCWgghhLBCEtBCCCGEFZKAFkIIIayQBLQQQghhhSSghRBCCCskAS2EEEJYIQloIYQQwgpJQAshhBBWSAJaCCGEsEIS0EIIIYQVkoAWQgghrJAEtBBCCGGFJKCFEEIIKyQBLYQQQlghCWghhBDCCklACyGEEFbo/wFbF8Ifp64Z8AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ethnicity_counts = clean_diabetes_df['ethnicity'].value_counts()#.plot(kind='pie', autopct='%1.1f%%')\n",
        "plt.pie(ethnicity_counts,labels=ethnicity_counts.index,autopct='%.1f%%');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGN6EAICOfnz"
      },
      "source": [
        "# Compile, Train, and Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "LLmBWFHXOf7F",
        "outputId": "80af4495-95f8-41e3-adcc-8982da5067c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "a:\\Programming\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,230</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m)             │         \u001b[38;5;34m4,230\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m3,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m41\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,911</span> (30.90 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,911\u001b[0m (30.90 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,911</span> (30.90 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,911\u001b[0m (30.90 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Modelmodel - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "# setting initial layer with 90 neurons (~2x # of inputs)\n",
        "# input_dim is 46 because of the transformed # of input columns after get_dummies\n",
        "nn.add(tf.keras.layers.Dense(units=90, activation='relu', input_dim=46))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=40, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "# use sigmoid activation function here because predicting binary classification\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZGvFS-G4PZ-L"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CX1h-5SOPcXx",
        "outputId": "ba668803-c5d6-4718-86b5-2124ec20ed8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - accuracy: 0.7139 - loss: 2.9955\n",
            "Epoch 2/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7599 - loss: 0.6072\n",
            "Epoch 3/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7626 - loss: 0.5910\n",
            "Epoch 4/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.7606 - loss: 0.6317\n",
            "Epoch 5/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7699 - loss: 0.5587\n",
            "Epoch 6/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7720 - loss: 0.5279\n",
            "Epoch 7/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.7758 - loss: 0.5166\n",
            "Epoch 8/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7779 - loss: 0.4917\n",
            "Epoch 9/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7810 - loss: 0.4733\n",
            "Epoch 10/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7853 - loss: 0.4759\n",
            "Epoch 11/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.7839 - loss: 0.4611\n",
            "Epoch 12/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7836 - loss: 0.4623\n",
            "Epoch 13/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7907 - loss: 0.4461\n",
            "Epoch 14/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.7878 - loss: 0.4511\n",
            "Epoch 15/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.7914 - loss: 0.4403\n",
            "Epoch 16/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.7931 - loss: 0.4420\n",
            "Epoch 17/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.7917 - loss: 0.4412\n",
            "Epoch 18/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7907 - loss: 0.4346\n",
            "Epoch 19/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7884 - loss: 0.4344\n",
            "Epoch 20/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7993 - loss: 0.4237\n",
            "Epoch 21/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.7940 - loss: 0.4226\n",
            "Epoch 22/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.8021 - loss: 0.4207\n",
            "Epoch 23/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7919 - loss: 0.4312\n",
            "Epoch 24/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8002 - loss: 0.4220\n",
            "Epoch 25/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7960 - loss: 0.4263\n",
            "Epoch 26/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7995 - loss: 0.4206\n",
            "Epoch 27/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7939 - loss: 0.4300\n",
            "Epoch 28/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.8000 - loss: 0.4182\n",
            "Epoch 29/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.7951 - loss: 0.4203\n",
            "Epoch 30/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8033 - loss: 0.4149\n",
            "Epoch 31/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7970 - loss: 0.4176\n",
            "Epoch 32/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.7986 - loss: 0.4203\n",
            "Epoch 33/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7999 - loss: 0.4192\n",
            "Epoch 34/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8036 - loss: 0.4148\n",
            "Epoch 35/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7993 - loss: 0.4175\n",
            "Epoch 36/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7998 - loss: 0.4131\n",
            "Epoch 37/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8001 - loss: 0.4174\n",
            "Epoch 38/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7988 - loss: 0.4138\n",
            "Epoch 39/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7986 - loss: 0.4212\n",
            "Epoch 40/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.8036 - loss: 0.4080\n",
            "Epoch 41/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8037 - loss: 0.4081\n",
            "Epoch 42/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8057 - loss: 0.4090\n",
            "Epoch 43/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8009 - loss: 0.4146\n",
            "Epoch 44/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8012 - loss: 0.4069\n",
            "Epoch 45/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8031 - loss: 0.4103\n",
            "Epoch 46/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8071 - loss: 0.4077\n",
            "Epoch 47/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8036 - loss: 0.4118\n",
            "Epoch 48/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8035 - loss: 0.4095\n",
            "Epoch 49/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8025 - loss: 0.4095\n",
            "Epoch 50/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8039 - loss: 0.4122\n",
            "Epoch 51/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.8013 - loss: 0.4143\n",
            "Epoch 52/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8039 - loss: 0.4051\n",
            "Epoch 53/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.8058 - loss: 0.4069\n",
            "Epoch 54/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8044 - loss: 0.4111\n",
            "Epoch 55/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8068 - loss: 0.4073\n",
            "Epoch 56/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8025 - loss: 0.4111\n",
            "Epoch 57/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8052 - loss: 0.4041\n",
            "Epoch 58/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.8060 - loss: 0.4053\n",
            "Epoch 59/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.8050 - loss: 0.4063\n",
            "Epoch 60/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.8037 - loss: 0.4040\n",
            "Epoch 61/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8041 - loss: 0.4064\n",
            "Epoch 62/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.8083 - loss: 0.4000\n",
            "Epoch 63/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8045 - loss: 0.4072\n",
            "Epoch 64/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8060 - loss: 0.4050\n",
            "Epoch 65/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.8039 - loss: 0.4052\n",
            "Epoch 66/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8065 - loss: 0.4042\n",
            "Epoch 67/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8036 - loss: 0.4020\n",
            "Epoch 68/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.8086 - loss: 0.4020\n",
            "Epoch 69/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.8044 - loss: 0.4066\n",
            "Epoch 70/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8072 - loss: 0.4038\n",
            "Epoch 71/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.8104 - loss: 0.3993\n",
            "Epoch 72/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8057 - loss: 0.4028\n",
            "Epoch 73/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8067 - loss: 0.4015\n",
            "Epoch 74/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8114 - loss: 0.3968\n",
            "Epoch 75/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.8114 - loss: 0.3981\n",
            "Epoch 76/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.8099 - loss: 0.3976\n",
            "Epoch 77/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.8086 - loss: 0.3966\n",
            "Epoch 78/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8115 - loss: 0.3949\n",
            "Epoch 79/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8131 - loss: 0.3905\n",
            "Epoch 80/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.8117 - loss: 0.3931\n",
            "Epoch 81/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.8096 - loss: 0.3953\n",
            "Epoch 82/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.8140 - loss: 0.3911\n",
            "Epoch 83/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.8108 - loss: 0.3931\n",
            "Epoch 84/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.8122 - loss: 0.3983\n",
            "Epoch 85/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.8088 - loss: 0.3957\n",
            "Epoch 86/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.8131 - loss: 0.3910\n",
            "Epoch 87/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8125 - loss: 0.3949\n",
            "Epoch 88/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8116 - loss: 0.3946\n",
            "Epoch 89/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.8144 - loss: 0.3909\n",
            "Epoch 90/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.8161 - loss: 0.3906\n",
            "Epoch 91/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.8152 - loss: 0.3889\n",
            "Epoch 92/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.8073 - loss: 0.3977\n",
            "Epoch 93/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.8109 - loss: 0.3915\n",
            "Epoch 94/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.8114 - loss: 0.3944\n",
            "Epoch 95/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.8143 - loss: 0.3891\n",
            "Epoch 96/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8148 - loss: 0.3957\n",
            "Epoch 97/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.8131 - loss: 0.3872\n",
            "Epoch 98/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.8128 - loss: 0.3913\n",
            "Epoch 99/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.8116 - loss: 0.3892\n",
            "Epoch 100/100\n",
            "\u001b[1m895/895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.8107 - loss: 0.3955\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "trained = nn.fit(X_train, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE8oNdl4bn5t"
      },
      "source": [
        "# Analyze Features and Tune Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcVhLSmgbnhM",
        "outputId": "c8948a86-96ca-4f02-839a-7dbeaa6c99f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikeras in a:\\programming\\anaconda3\\lib\\site-packages (0.13.0)\n",
            "Requirement already satisfied: scikit-learn in a:\\programming\\anaconda3\\lib\\site-packages (1.5.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in a:\\programming\\anaconda3\\lib\\site-packages (from scikeras) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in a:\\programming\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in a:\\programming\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in a:\\programming\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in a:\\programming\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py in a:\\programming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
            "Requirement already satisfied: rich in a:\\programming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (13.3.5)\n",
            "Requirement already satisfied: namex in a:\\programming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in a:\\programming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
            "Requirement already satisfied: optree in a:\\programming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in a:\\programming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\nikki\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.2.0->scikeras) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\nikki\\appdata\\roaming\\python\\python311\\site-packages (from optree->keras>=3.2.0->scikeras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in a:\\programming\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nikki\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.2.0->scikeras) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in a:\\programming\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.0)\n",
            "Requirement already satisfied: scipy in a:\\programming\\anaconda3\\lib\\site-packages (1.11.4)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
            "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
            "     -------------------- ------------------- 30.7/60.8 kB 1.4 MB/s eta 0:00:01\n",
            "     -------------------------------------- 60.8/60.8 kB 815.1 kB/s eta 0:00:00\n",
            "Requirement already satisfied: scikit-learn in a:\\programming\\anaconda3\\lib\\site-packages (1.5.1)\n",
            "Requirement already satisfied: scikeras in a:\\programming\\anaconda3\\lib\\site-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in a:\\programming\\anaconda3\\lib\\site-packages (from scipy) (1.26.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in a:\\programming\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in a:\\programming\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in a:\\programming\\anaconda3\\lib\\site-packages (from scikeras) (3.5.0)\n",
            "Requirement already satisfied: absl-py in a:\\programming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
            "Requirement already satisfied: rich in a:\\programming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (13.3.5)\n",
            "Requirement already satisfied: namex in a:\\programming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in a:\\programming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
            "Requirement already satisfied: optree in a:\\programming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in a:\\programming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\nikki\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.2.0->scikeras) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\nikki\\appdata\\roaming\\python\\python311\\site-packages (from optree->keras>=3.2.0->scikeras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in a:\\programming\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nikki\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.2.0->scikeras) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in a:\\programming\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.0)\n",
            "Downloading scipy-1.14.1-cp311-cp311-win_amd64.whl (44.8 MB)\n",
            "   ---------------------------------------- 0.0/44.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.2/44.8 MB 4.5 MB/s eta 0:00:10\n",
            "    --------------------------------------- 0.6/44.8 MB 7.4 MB/s eta 0:00:06\n",
            "   - -------------------------------------- 1.2/44.8 MB 9.3 MB/s eta 0:00:05\n",
            "   - -------------------------------------- 2.0/44.8 MB 11.5 MB/s eta 0:00:04\n",
            "   -- ------------------------------------- 2.6/44.8 MB 11.9 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 3.6/44.8 MB 13.4 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 4.4/44.8 MB 14.0 MB/s eta 0:00:03\n",
            "   ---- ----------------------------------- 5.3/44.8 MB 14.6 MB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 5.7/44.8 MB 14.0 MB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 6.3/44.8 MB 13.8 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 7.1/44.8 MB 14.2 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 7.5/44.8 MB 14.0 MB/s eta 0:00:03\n",
            "   ------- -------------------------------- 8.3/44.8 MB 14.4 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 9.1/44.8 MB 14.2 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 9.9/44.8 MB 14.4 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 10.7/44.8 MB 15.6 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 10.9/44.8 MB 14.9 MB/s eta 0:00:03\n",
            "   ---------- ----------------------------- 11.6/44.8 MB 14.9 MB/s eta 0:00:03\n",
            "   ----------- ---------------------------- 12.4/44.8 MB 15.2 MB/s eta 0:00:03\n",
            "   ----------- ---------------------------- 13.0/44.8 MB 15.2 MB/s eta 0:00:03\n",
            "   ------------ --------------------------- 13.7/44.8 MB 14.9 MB/s eta 0:00:03\n",
            "   ------------- -------------------------- 14.6/44.8 MB 14.9 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 15.7/44.8 MB 15.6 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 16.7/44.8 MB 16.0 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 17.4/44.8 MB 16.4 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 18.2/44.8 MB 16.4 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 18.9/44.8 MB 16.4 MB/s eta 0:00:02\n",
            "   ----------------- ---------------------- 19.4/44.8 MB 16.0 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 20.3/44.8 MB 16.0 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 21.0/44.8 MB 16.0 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 21.6/44.8 MB 16.8 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 22.2/44.8 MB 16.8 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 23.2/44.8 MB 16.8 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 23.9/44.8 MB 17.2 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 24.6/44.8 MB 16.8 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 25.4/44.8 MB 16.0 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 25.8/44.8 MB 15.2 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 26.3/44.8 MB 15.2 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 27.0/44.8 MB 14.9 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 28.0/44.8 MB 15.2 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 28.5/44.8 MB 14.9 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 29.3/44.8 MB 14.9 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 30.1/44.8 MB 14.9 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 30.9/44.8 MB 15.2 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 31.6/44.8 MB 15.6 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 32.5/44.8 MB 16.0 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 33.3/44.8 MB 15.6 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 34.0/44.8 MB 15.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 34.8/44.8 MB 16.0 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 35.1/44.8 MB 16.0 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 36.6/44.8 MB 17.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 37.1/44.8 MB 16.8 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 37.9/44.8 MB 17.2 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 38.9/44.8 MB 16.8 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 39.9/44.8 MB 17.3 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 40.6/44.8 MB 17.7 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 41.5/44.8 MB 17.7 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 42.0/44.8 MB 17.7 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 42.4/44.8 MB 16.8 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 42.9/44.8 MB 16.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  44.1/44.8 MB 16.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  44.8/44.8 MB 17.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  44.8/44.8 MB 17.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  44.8/44.8 MB 17.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  44.8/44.8 MB 17.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  44.8/44.8 MB 17.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  44.8/44.8 MB 17.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  44.8/44.8 MB 17.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  44.8/44.8 MB 17.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 44.8/44.8 MB 10.7 MB/s eta 0:00:00\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "Successfully installed scipy-1.14.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'A:\\Programming\\anaconda3\\Lib\\site-packages\\~cipy'.\n",
            "  You can safely remove it manually.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras scikit-learn\n",
        "!pip install --upgrade scipy scikit-learn scikeras\n",
        "#!pip install scipy==1.13.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "-tLxFk-j6eXx",
        "outputId": "915650b0-87fb-4feb-dd90-3e5c110ca1e8"
      },
      "outputs": [],
      "source": [
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "J2ustCNd6ifM",
        "outputId": "3e5bdee1-ec59-4a2c-9d89-fc7484de2158"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weakest feature: height with importance -0.0016549701476903378\n",
            "Weakest feature: heart_rate_apache with importance -0.0008065360846338798\n",
            "Weakest feature: apache_post_operative with importance -0.000785587095422613\n",
            "Weakest feature: gcs_eyes_apache with importance -0.0005237247302817494\n",
            "Weakest feature: intubated_apache with importance -0.00042945427883103184\n",
            "Weakest feature: d1_spo2_min with importance -0.0003037603435633751\n",
            "Weakest feature: map_apache with importance -0.0002932858489577472\n",
            "Weakest feature: d1_temp_max with importance -0.00024091337592957451\n",
            "Weakest feature: d1_temp_min with importance -0.00021996438671828544\n",
            "Weakest feature: gcs_motor_apache with importance -0.00020948989211266866\n",
            "Weakest feature: d1_mbp_max with importance -9.427045145068424e-05\n",
            "Weakest feature: d1_heartrate_min with importance -7.332146223941738e-05\n",
            "Weakest feature: d1_mbp_min with importance -6.28469676338006e-05\n",
            "Weakest feature: ethnicity_Hispanic with importance -5.237247302813941e-05\n",
            "Weakest feature: gender_M with importance -3.1423483816872545e-05\n",
            "Weakest feature: lymphoma with importance -2.0948989211244663e-05\n",
            "Weakest feature: leukemia with importance 4.4408920985006264e-17\n",
            "Weakest feature: hepatic_failure with importance 3.1423483816939156e-05\n",
            "Weakest feature: ethnicity_Asian with importance 4.189797842257814e-05\n",
            "Weakest feature: ethnicity_Native American with importance 8.379595684511187e-05\n"
          ]
        }
      ],
      "source": [
        "# Ensure that nn is defined as your Keras model\n",
        "# Define the wrapped model (assuming nn is your Keras Sequential model)\n",
        "wrapped_nn = KerasClassifier(model=nn, epochs=20, batch_size=32, verbose=0)\n",
        "\n",
        "# Train the wrapped model\n",
        "wrapped_nn.fit(X_train, y_train)\n",
        "\n",
        "# Compute permutation importance\n",
        "result = permutation_importance(wrapped_nn, X_test, y_test, n_repeats=10, random_state=10)\n",
        "\n",
        "# Get feature importances\n",
        "importances = result.importances_mean\n",
        "\n",
        "# Ensure X_test is a DataFrame or convert it\n",
        "if not isinstance(X_test, pd.DataFrame):\n",
        "    X_test = pd.DataFrame(X_test, columns=X_test.columns)\n",
        "\n",
        "# Sort the features by importance in ascending order (weakest to strongest)\n",
        "sorted_indices = np.argsort(importances)\n",
        "\n",
        "# Get the top 20 weakest features\n",
        "top_20_weakest_indices = sorted_indices[:20]\n",
        "top_20_weakest_features = X_test.columns[top_20_weakest_indices]\n",
        "top_20_weakest_importances = importances[top_20_weakest_indices]\n",
        "\n",
        "# Display the weakest features and their importances\n",
        "for feature, importance in zip(top_20_weakest_features, top_20_weakest_importances):\n",
        "    print(f\"Weakest feature: {feature} with importance {importance}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Strongest feature: d1_glucose_max with importance 0.08978736775950563\n",
            "Strongest feature: d1_glucose_min with importance 0.005970461925212145\n",
            "Strongest feature: d1_heartrate_max with importance 0.0033413637791977037\n",
            "Strongest feature: bmi with importance 0.0033308892845920536\n",
            "Strongest feature: glucose_apache with importance 0.0031423483816906185\n",
            "Strongest feature: apache_2_diagnosis with importance 0.002587200167591952\n",
            "Strongest feature: apache_3j_diagnosis with importance 0.0022834398240285216\n",
            "Strongest feature: arf_apache with importance 0.0017911385775636669\n",
            "Strongest feature: age with importance 0.0017806640829580388\n",
            "Strongest feature: d1_sysbp_min with importance 0.0017701895883523889\n",
            "Strongest feature: d1_diasbp_min with importance 0.0016968681261129604\n",
            "Strongest feature: resprate_apache with importance 0.0015606996962396868\n",
            "Strongest feature: d1_diasbp_max with importance 0.0014664292447889693\n",
            "Strongest feature: weight with importance 0.001340735309521357\n",
            "Strongest feature: gcs_eyes_apache with importance 0.0011836178904368277\n",
            "Strongest feature: heart_rate_apache with importance 0.0009950769875353815\n",
            "Strongest feature: gcs_verbal_apache with importance 0.0008903320414790361\n",
            "Strongest feature: gcs_motor_apache with importance 0.0005656227087043498\n",
            "Strongest feature: d1_spo2_max with importance 0.0005027757410705269\n",
            "Strongest feature: ethnicity_Other/Unknown with importance 0.0003875563004085425\n"
          ]
        }
      ],
      "source": [
        "# Wrap your Keras model\n",
        "wrapped_nn = KerasClassifier(model=nn, epochs=20, batch_size=32, verbose=0)\n",
        "\n",
        "# Train the wrapped model\n",
        "wrapped_nn.fit(X_train, y_train)\n",
        "\n",
        "# Compute permutation importance\n",
        "result = permutation_importance(wrapped_nn, X_test, y_test, n_repeats=10, random_state=10)\n",
        "\n",
        "# Get feature importances\n",
        "importances = result.importances_mean\n",
        "\n",
        "# Sort the features by importance in descending order (strongest to weakest)\n",
        "sorted_indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Get the top 20 strongest features\n",
        "top_20_strongest_indices = sorted_indices[:20]\n",
        "top_20_strongest_features = X_test.columns[top_20_strongest_indices]\n",
        "top_20_strongest_importances = importances[top_20_strongest_indices]\n",
        "\n",
        "# Display the strongest features and their importances\n",
        "for feature, importance in zip(top_20_strongest_features, top_20_strongest_importances):\n",
        "    print(f\"Strongest feature: {feature} with importance {importance}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
